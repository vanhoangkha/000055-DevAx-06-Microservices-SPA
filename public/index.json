[
{
	"uri": "/",
	"title": "Creating an Authenticated Single Page Application (SPA) ",
	"tags": [],
	"description": "",
	"content": "Creating an Authenticated Single Page Application (SPA) Oveview In this lab we will iterate on our TravelBuddy monolithic implementation, and move it to a serverless/serviceful architecture, with microservices. In previous Labs, we have looked at various serverless concepts - for example, AWS Lambda and Amazon API Gateway - but in this lab, we will rethink our monolith, move to a completely serverless model and incorporate authentication and authorisation using Amazon Cognito.\nYou will take various approaches when deploying the Lambda functions that make up the microservices, from manual deployment to automated CI/CD deployment, to ensure you have a good understanding of each of parts of the architecture, and how infrastructure automation simplifies and streamlines deployment.\nContent: Introduction Preparation Creating A Single Page Application Configure Authentication, Authorization and Accounting (AAA) Tracing Application Performance With AWS X-Ray Challenge Clean up resources "
},
{
	"uri": "/2-spa/1-prerequisites/a/",
	"title": "Eclipse Environment",
	"tags": [],
	"description": "",
	"content": "In this exercise, you will connect to your Windows Development host. We will be using the provided Windows Development environment to run this lab.\nContents\nInstall \u0026amp; Configure Prerequisites - Windows Eclipse Development DynamoDB Setup Install \u0026amp; Configure Prerequisites - Windows Eclipse Development In this exercise, you will connect to your Windows Development host. We will be using the provided Windows Development environment to run this lab. You will need to configure your windows instances and install the AWS CLI.\nAn AWS EC2 windows instance has been set up for you. To gain access to the Workspace, follow the instructions outlined in Section 1.2 - Remote enviroment \u0026amp; Configure the AWS CLI, then continue this lab: DynamoDB Setup We need to populate a DynamoDB table with information that will be used during the lab. This information will be used to calculate trips between different cities.\nOnly complete this step after your Windows eclipse environment has been set up.\nDownload the following file to your Windows Eclipse environment: populate_tripsector.sh DB file\rpopulate_tripsector.sh\r(1 ko)\rExecute the following in your Windows Eclipse Environment. You will need to use git bash that has been included in your installation. bash populate_tripsector.sh \u0026lt;AWS_REGION\u0026gt; Open the DynamoDB service in the console and check the table TravelBuddyTripSectors table and confirm there are 50 rows in the table. "
},
{
	"uri": "/2-spa/4-codestar-cicd/a/",
	"title": "Eclipse Environment",
	"tags": [],
	"description": "",
	"content": "The next microservice we need for our TravelBuddy serverless application is the FlightSpecials API. We have seen FlightSpecials before in this course, so it should be familiar to you. It functions the same way as the HotelSpecials API in that it must be deployed with VPC integration so it can connect to the MySQL database to query for data. Instead of manually packaging and deploying this microservice, we will use CodeStar to build out a full CI/CD pipeline for us, as we have done in previous labs. So, since you have created CI/CD pipelines using AWS CodeStar a few times now, we are not going to provide you with full step-by-step instructions. If you need help, ask a Lab Assistant how to complete the tasks required to create a new CodeStar project and deploy the FlightSpecials code over the sample application provided by CodeStar.\nContents\nCreate a CI/CD pipeline with AWS CodeStar Update placeholder parameters in the CloudFormation template Update the target AWS region in the swagger.yml API definition file Check changes into source control to trigger a deploy Test the FlightSpecials API Create a CI/CD pipeline with AWS CodeStar Create a new AWS CodeStar Web Service project targeting Java on AWS Lambda. Call the project FlightSpecialsAPI. If you need help with this task, see the CodeStar documentation. Import the CodeStar project into the Eclipse IDE. See the documentation if you need help with this. Remember, your Git credentials for this Lab are provided in output section of the CloudFormation template. If using Cloud9 remember to add the git config helpers. Right-click FlightSpecials and save the file to your local machine. Explode the ZIP file. FlightSpecials source code\rFlightSpecials.zip\r(18 ko)\rCreate a new branch in git for the new implementation you are about to create. Call the new branch new-implementation Overwrite the implementation provided by CodeStar with the contents of the ZIP file you just exploded. We have provided a copy_files.sh script in the FlightSpecials.zip bundle that you can use, as before in previous lab exercises. To use it, run the below command by replacing path/to/your/working/folder E.G.: copy_files.sh /path/to/your/working/folder Don\u0026rsquo;t forget to use the Maven | Update Project feature of the Eclipse IDE to \u0026lsquo;rethink\u0026rsquo; the project after the change to the source code.\nGive CloudFormation permission to create an IAM role\nAs part of our microservice setup, we will be assigning a new IAM Role to our Lambda function to allow it to perform various tasks. When CodeStar created our project, it created an IAM Role that gave CloudFormation just enough permissions to deploy the Hello World example service. These permissions are not enough for our more advanced requirements. So we need to adjust the policies assigned to the CloudFormation role, to extend those permissions.\nOpen the AWS IAM Console in the browser. Click Roles on the navigation pane. In the Filter box, type CodeStarWorker-flightspecialsa-CloudFormation to locate the correct IAM Role. If you can\u0026rsquo;t find the role, it may be too early - CodeStar may still be provisioning the pipeline and may not yet have created the role. Check the progress of the provisioning in the CodeStar dashboard.\nClick on the role to open the details panel. Click Attach Policy, in the Filter box, type idevelop to shortlist the available policies. Select the idevelopCodeStarCloudFormationPolicy policy shown in the list. This policy has been created for you by the lab setup process, and has the permissions assigned to it to allow CloudFormation to work on our behalf when creating the Lambda execution role. Select the listed policy and click Attach Policy Update placeholder parameters in the CloudFormation template The CloudFormation template template.yml that was provided as part of the FlightSpecials.zip file has some placeholder values that you need to update to match the values from your lab account before you can deploy the updates. These include Subnet Ids, Security Group Ids and the RDS Instance Endpoint, which are unique to your lab account and unknown at this stage to the template. In the Eclipse IDE, open the template.yml file and search for each of the items in the table below in the Replace column, and replace them with the values that are found in Cloudformation Outputs tab:\nItem to replace Description \u0026lt;DatabaseSubnet1\u0026gt; First network subnet for the mySQL database \u0026lt;DatabaseSubnet2\u0026gt; Second network subnet for the mySQL database \u0026lt;DatabaseSecurityGroup\u0026gt; The security group for the mySQL database \u0026lt;RDSEndpoint\u0026gt; The mySQL database endpoint When you\u0026rsquo;ve completed updating the values, the VPCConfig section will look similar to this (with different values): VpcConfig: SecurityGroupIds: - sg-858e61e3 SubnetIds: - subnet-3c989d4a - subnet-a04255c4 Environment: Variables: JDBC_CONNECTION_STRING: jdbc:mysql://qlxx5jzrxxxby.cig0rzmdedgf.ap-northeast-1.rds.amazonaws.com:3306/travelbuddy?useSSL=false\u0026amp;serverTimezone=UTC\u0026amp;autoReconnect=true JDBC_UID: root JDBC_PWD: labpassword Update the target AWS region in the swagger.yml API definition file The swagger.yml file provided in the zip bundle is the definition for the API that exposes the microservice via Amazon API Gateway. It needs to be updated with details of your lab AWS Account Id and target AWS Region before you can deploy your microservice.\nIn the Eclipse IDE, locate the swagger.yml file and open it in the text editor Search for the text REPLACE_AWS_REGION and replace it with the region you are using (for example, ap-northeast-1) Search for the text REPLACE_AWS_ACCOUNTID and replace it with the your AWS Account Id. You can find your AWS Account Id in the lab dashboard. Save the file. Check changes into source control to trigger a deploy Now that you have completed updating files, you need to add the changed files to your new-implementation git branch and commit the files. You can use the Eclipse IDE or the commandline. In this example, we will use the commandline, but note for the final push you will need to use the Eclipse IDE since it is configured with your Git credentials, whereas the commandline has not: Issue git status to review the changed code files Issue git add . to add in the changed files Issue git commit -m \u0026quot;Baseline implementation\u0026quot; to commit the changes and provide a message Issue git checkout master to switch back to the master branch Now merge the changes for your new implementation into the master branch by issuing git merge new-implementation Push the changes to CodeCommit using Eclipse by right-clicking the project root and click Team | Push to Origin\u0026hellip; You need to perform the push from Eclipse because the git credentials are embedded within the Eclipse environment. You could also configure the command line environment with the git credentials but that is beyond the scope of this lab.\nIt will take a few moments to push the code and commence the deployment. Checking in the source code and templates will trigger the pipeline to build and deploy the new implementation. AWS CodePipeline will now use CloudFormation to deploy the following resources:\nThe Lambda function implemented by the Java code you checked into CodeCommit IAM role for the Lambda function API Gateway configuration for the API While you have some time, spend a few minutes to explore the buildspec.yml, swagger.yml and template.yml files which define the Amazon API Gateway, AWS Lambda function and the build/deployment process through AWS CodeBuild. You will notice that the builspec.yml file uses the same AWS CLI command to package the deployment that you used when you manually packaged the HotelSpecials API earlier.\nDo not execute these commands below, they are here as a reference!\nmvn package shade:shade aws cloudformation package --template template.yml --s3-bucket $S3_BUCKET --output-template template-export.yml The template.yml file uses the Serverless Application Model (SAM) transform to define the REST API, as opposed to how we approached this in the HotelSpecials API example. In HotelSpecials, the CloudFormation template used canonical CloudFormation to define the REST API so that it could be explicit about the API definition and include the swagger definition inline. The FlightSpecials example uses a more declarative approach and left the details to SAM. You are free to mix CloudFormation and SAM in the same template, as you can see from these examples.\nNote that the $S3_BUCKET environment variable is automatically replaced by CodeBuild when the build step is performed, and replaced by the S3 Bucket that CodeStar provisioned when it set up the project.\nTest the FlightSpecials API You can check the status of the deployment of the code change through the pipeline back on the CodeStar project dashboard. Once the deployment has completed through the CI/CD pipeline, you are ready to test the API.\nOpen the API Gateway console in the browser and under APIs, click the iDevelop - Flight Specials API link to reveal the resources for the API. Click on the Stages link beneath the iDevelop - Flight Specials API. Expand the prod root element in the Stages list to reveal the hierarchy. Click on the GET method Click on the Invoke URL value in the prod - GET - /flightspecials panel. After a moment while the Lambda function is initialised, you should see the JSON result of querying the mySQL database from the Lambda function. For example: { \u0026#34;succeeded\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;errorCode\u0026#34;: 0, \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;header\u0026#34;: \u0026#34;London to Prague\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Jewel of the East\u0026#34;, \u0026#34;cost\u0026#34;: 93, \u0026#34;expiryDate\u0026#34;: 1504072439813 }, { \u0026#34;id\u0026#34;: 2, \u0026#34;header\u0026#34;: \u0026#34;Paris to London\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Weekend getaway!\u0026#34;, \u0026#34;cost\u0026#34;: 182, \u0026#34;expiryDate\u0026#34;: 1504074888702 } ] } If you see a JSON payload with no errors, you have successfully deployed an API and supporting Lambda function that queries the mySQL database. Notice how much quicker and easier that was to deploy without any manual intervention, and you didn\u0026rsquo;t even have to interact with the AWS CLI or Console? Everything was driven by the source control check-in process.\nYou are now ready to integrate these APIs with the TravelBuddy web site.\n"
},
{
	"uri": "/2-spa/1-prerequisites/",
	"title": "Pre-requisites",
	"tags": [],
	"description": "",
	"content": "In this exercise, you will have the option to continue developing on the windows based eclipse environment or utilise a cloud based development using AWS Cloud9. AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser.\nIf you haven’t used Cloud9 before, this is an excellent opportunity to use a cloud-based integrated development environment! Whether you choose to develop on AWS Cloud9 or continue to use the Windows based environment provided by this module you will still be able to cover all the topics of the lab.\nContents\nOption A: Eclipse Environment Option B: AWS Cloud9 Environment "
},
{
	"uri": "/1-prerequisites/",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "Welcome to the first module in this workshop! This module involves getting access to a developer environment that we’ve provisioned for you. The developer environment contains all the software and network access required to get you up and running with the labs in record time.\nWe’ve chosen to do this as the main aim for this workshop is learning the content in each module, not setting up your local machines. It also provides a consistent environment between you and your fellow colleagues to eliminate the weird “works on my machine” behavior.\nIf you were planning on running this lab on your own machine, you’ll have to adapt the instructions accordingly. Make sure to manually install the software listed in the Development Environment section below.\nContents\nTopics Covered Development Environment Topics Covered By the end of this lab, you will be able to:\nConnect to a running windows instance\nDevelopment Environment A fully fledged development environment has already been created for you with the following resources installed:\nJava 8 JDK Apache Maven Eclipse IDE for Java EE Developers Tomcat 9 AWS Toolkit for eclipse AWS CLI Elastic Beanstalk CLI "
},
{
	"uri": "/4-configure-aaa/4.1-add-authentication-with-cognito/",
	"title": "Add Authentication to the SPA using Amazon Cognito User Pools",
	"tags": [],
	"description": "",
	"content": "Add Authentication to the SPA using Amazon Cognito User Pools In this exercise, we will make use of the Cognito User Pool and Identity Pool, and mark one of our API endpoints as requiring authentication via Cognito User Pools.\nGo to AWS Cognito console. Click User pools Click TravelBuddy Save the User pool ID value Click App integration Save the Client ID value of the App client name whose name is TravelBuddyWebApp Click Federated Identities Click TravelBuddy Click Sample code In the Get AWS Credentials section, save the Identity Pool ID value displayed in the sample code Open the file whose path is www\\scripts\\webapp-configuration.js in the www folder we extracted in step 1 of the 3.5 section The SPA is implemented using the Angular framework, which allows you to define global constants that are used as configuration variables throughout your application. This file defines the values of the configuration variables that you need to set based on your AWS Account’s ARNs and Ids for the various Cognito resources\nReplace REPLACE_WITH_COGNITO_IDENTITY_POOL_ID with the Identity Pool ID value we saved in step 6 Replace REPLACE_WITH_COGNITO_USER_POOL with the User pool ID value we saved in step 2 Replace REPLACE_WITH_COGNITO_USER_POOL_CLIENT_ID with the Client ID value we saved in step 3 Replace REPLACE_WITH_S3_BUCKET_WWW with the S3BucketWWWBucketName value in the Output tab of the DevAx-06 stack In the AWS_REGION field replace with your Region Save Open Command Prompt, navigate to the directory of the www folder we extracted in step 1 in the 3.5 section Execute the following command to upload the changes to the S3BucketWWWBucketName bucket set AWS_PROFILE=devaxacademy\raws s3 sync . s3://\u0026lt;S3BucketWWWBucketName\u0026gt; Replace \u0026lt;S3BucketWWWBucketName\u0026gt; with the S3BucketWWWBucketName value in the Output tab of the DevAx-06 stack\n10. Refresh the TravelBuddy web page and check the developer console to confirm there are no errors following the changes you have made.\n"
},
{
	"uri": "/3-create-single-page-app/3.1-create-dynamodb-table/",
	"title": "Create A DynamoDB Table",
	"tags": [],
	"description": "",
	"content": "Create A DynamoDB Table populate_tripsector.sh\rpopulate_tripsector.sh\r(1 ko)\rDownload populate_tripsector.sh file to Downloads folder in the Windows virtual machine. Open Command Prompt Execute the below command: set AWS_DEFAULT_PROFILE=devaxacademy\rcd Downloads\rpopulate_tripsector.sh \u0026lt;YOUR_REGION\u0026gt; Replace \u0026lt;YOUR_REGION\u0026gt; by your Region\nGo to AWS DynamoDB Console. Click Explore items Type TravelBuddyTripSectors in the search bar and press Enter Select TravelBuddyTripSectors In Items returned section, You will see 50 records. "
},
{
	"uri": "/2-prepare/2.1-createkeypair/",
	"title": "Create Key Pair",
	"tags": [],
	"description": "",
	"content": "Create Key Pair Go to Amazon EC2 console. On the left navigation bar, click Key Pairs. Click Create key pair. In the Create key pair page In the Name section, type KPforDevAxInstances In the Key pair type section, Select RSA In the Private key file format section, select .pem Click Create key pair Save file key pair to use in the next step. "
},
{
	"uri": "/1-introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction In this lab we will iterate on our TravelBuddy monolithic implementation, and move it to a serverless/serviceful architecture, with microservices. In previous Labs, we have looked at various serverless concepts - for example, AWS Lambda and Amazon API Gateway - but in this lab, we will rethink our monolith, move to a completely serverless model and incorporate authentication and authorisation using Amazon Cognito.\nYou will take various approaches when deploying the Lambda functions that make up the microservices, from manual deployment to automated CI/CD deployment, to ensure you have a good understanding of each of parts of the architecture, and how infrastructure automation simplifies and streamlines deployment.\nThe overall architecture you will build is as follows:\nAmazon Cognito Amazon Cognito lets you easily add user sign-up and sign-in to your mobile and web apps. With Amazon Cognito, you also have the options to authenticate users through social identity providers such as Facebook, Twitter, or Amazon, with SAML identity solutions, or by using your own identity system.\nClick here for more information about Amazon Cognito\nAmazon API Gateway Amazon API Gateway is an AWS service that enables developers to create, publish, maintain, monitor, and secure APIs at any scale. You can create APIs that access AWS or other web services, as well as data stored in the AWS Cloud. API Gateway can be considered a backplane in the cloud to connect AWS services and other public or private web sites. It provides consistent RESTful application programming interfaces (APIs) for mobile and web applications to access AWS services.\nClick here for more information about Amazon API Gateway\nTopics Covered By the end of this lab, you will be able to:\nUnderstand how you can take a monolithic application and distill it down into a Single Page Web Application hosted on Amazon S3, with supporting business logic provided by Amazon API Gateway and AWS Lambda. Single Page Web Application hosted on Amazon S3, with supporting business logic provided by Amazon API Gateway and AWS Lambda Use the AWS Console to create and configure an Amazon Cognito User Pool and Identity Pool for use in your serverless application Manually deploy a Lambda function using the AWS CLI Manually deploy a Lambda function using the AWS CLI CloudFormation tool Manually configure an API in Amazon API Gateway Automate the full deployment of an API using CodeStar Generate SDKs from Amazon API Gateway Technical Knowledge Prerequisites To successfully complete this lab, you should be familiar with basic navigation of the AWS Management Console and have intermediate experience using the Eclipse IDE and the Java Programming language.\nEnvironment All the resources required to begin this lab have already been provisioned and set up for you. If running in your own account, use this CloudFormation template The following diagram depicts the resources that were deployed in your AWS account.\n"
},
{
	"uri": "/1-prerequisites/1-create-environment/",
	"title": "Create Environment",
	"tags": [],
	"description": "",
	"content": "All the resources required to begin this lab have already been provisioned and set up for you. If running in your own account, use this CloudFormation template\nOr download below and deploy to CloudFormation: CloudFormation Template\rModule6.template.yaml\r(52 ko)\rThe following diagram depicts the resources that were deployed in your AWS account.\nContents\nCreate a new Keypair Deploy CloudFormation Template Create a new Keypair If you already have a Keypair in your account, you can skip this step.\nTrước tiên, cần tạo một Keypair cho các máy ảo trong bài thực hành. Truy cập EC2 console, chọn Keypairs Chọn Create key pair Nhập tên keypair KPforDevAxInstances, chọn định dạng tập tin pem và chọn Create key pair Một cửa sổ xuất hiện để chọn nơi lưu trữ tập tin keypair. Bạn cần lưu trữ keypair này để truy cập vào máy ảo EC2 trong các bước sau Deploy CloudFormation Template Trong bài thực hành này, chúng ta sẽ sử dụng CloudFormation template đã cung cấp và cài đặt sẵn các tài nguyên cần thiết.\nTruy cập AWS CloudFormation Chọn Create stack, chọn With new resources (standard) Tại mục Prerequisite - Prepare template chọn Template is ready Tại mục Template source, chọn Upload a template file, nhấp chọn Choose file và trỏ tới file template đã tải xuống. Chọn Next Nhập tên stack tại mục Stack name (VD: DevAx-M2M-M5) Chọn keypair KPforDevAxInstances cho mục EEKeyPair và chọn Next Chọn Next tại trang Configure stack options Chọn Create stack Chúng ta cần chờ một vài phút để các tài nguyên được khởi tạo và cấu hình. "
},
{
	"uri": "/3-aaa/1-cognito/",
	"title": "SPA Authentication",
	"tags": [],
	"description": "",
	"content": "Add Authentication to the SPA using Amazon Cognito User Pools\nIn this exercise, we will make use of the Cognito User Pool and Identity Pool, and mark one of our API endpoints as requiring authentication via Cognito User Pools.\nOn your local filesystem, locate the file webapp-configuration.js in the scripts directory of the web site bundle you have downloaded and exploded. This file has the following contents: (function () { \u0026#39;use strict\u0026#39;; angular .module(\u0026#39;app\u0026#39;) .constant(\u0026#39;COGNITO_IDENTITY_POOL_ID\u0026#39;, \u0026#39;REPLACE_WITH_COGNITO_IDENTITY_POOL_ID\u0026#39;) .constant(\u0026#39;COGNITO_USER_POOL\u0026#39;, \u0026#39;REPLACE_WITH_COGNITO_USER_POOL\u0026#39;) .constant(\u0026#39;COGNITO_USER_POOL_CLIENT_ID\u0026#39;,\u0026#39;REPLACE_WITH_COGNITO_USER_POOL_CLIENT_ID\u0026#39;) .constant(\u0026#39;COGNITO_APP_WEB_DOMAIN\u0026#39;, \u0026#39;REPLACE_WITH_S3_BUCKET_WWW\u0026#39;) .constant(\u0026#39;AWS_REGION\u0026#39;, \u0026#39;ap-northeast-1\u0026#39;) .constant(\u0026#39;APP_BANNER\u0026#39;, \u0026#39;TravelBuddy\u0026#39;) })(); The SPA is implemented using the Angular framework, which allows you to define global constants that are used as configuration variables throughout your application. This file defines the values of the configuration variables that you need to set based on your AWS Account’s ARNs and Ids for the various Cognito resources. Open the webapp-configuration.js file in a text editor and keep it open while we make changes in the following steps.\nOpen the AWS Cognito console by clicking Services and typing cognito in the filter box. Press Enter. Click Manage your User Pools Click TravelBuddy In the General Settings panel that appears, locate the Pool Id value, and replace the text REPLACE_WITH_COGNITO_USER_POOL in the webapp-configuration.js file with the value. Click the App Client settings link beneath App integration in the left-hand navigation panel of the Cognito User Pools page. Locate the ID value beneath the App client TravelBuddyWebApp heading and copy it to your clipboard. For example: Replace the text REPLACE_WITH_COGNITO_USER_POOL_CLIENT_ID in the webapp-configuration.js file with the value of the App client ID. In the Cognito console, click Federated Identities at the top navigation bar to switch to the Cognito Identity Pools manager. Click the TravelBuddy link in the identity pool card that is shown. In the dashboard that appears, on the left navigation panel, click Sample code. In the Get AWS Credentials section, note the Identity Pool ID is displayed in the sample code. Copy the Identity Pool ID into your clipboard. It will look something like this: ap-northeast-1:aaaaaaaa-bbbb-cccc-dddd-eeeeeeeeee Make sure you copy the whole entry, including the region specifier.\nReplace the text REPLACE_WITH_COGNITO_IDENTITY_POOL_ID in the webapp-configuration.js file with the value of the Identity Pool Id. In the lab CloudFormation console, in the Additional Info panel, copy the value of S3BucketWWW which is the S3 bucket name for the web hosting bucket you are using to serve your SPA. Replace the text REPLACE_WITH_S3_BUCKET_WWW in the webapp-configuration.js file with the value of the S3BucketWWW from the Additional Info panel in lab. The finished webapp-configuration.js file will look something like this: (function () { \u0026#39;use strict\u0026#39;; angular .module(\u0026#39;app\u0026#39;) .constant(\u0026#39;COGNITO_IDENTITY_POOL_ID\u0026#39;, \u0026#39;ap-northeast-1:429c1d1c-7a5e-4d53-be18-177b806c53a4\u0026#39;) .constant(\u0026#39;COGNITO_USER_POOL\u0026#39;, \u0026#39;ap-northeast-1_YSRyht4ck\u0026#39;) .constant(\u0026#39;COGNITO_USER_POOL_CLIENT_ID\u0026#39;,\u0026#39;3mh9486bds2f2cr3gio8bdjoik\u0026#39;) .constant(\u0026#39;COGNITO_APP_WEB_DOMAIN\u0026#39;, \u0026#39;devax-m6-s3bucketwebsite18ddbcd4-19ewci3z6hece\u0026#39;) .constant(\u0026#39;AWS_REGION\u0026#39;, \u0026#39;ap-northeast-1\u0026#39;) .constant(\u0026#39;APP_BANNER\u0026#39;, \u0026#39;TravelBuddy\u0026#39;) })(); You have now made all the changes you need to in the webapp-configuration.js file. Save the file, and upload it to the S3BucketWWW in the scripts folder, to overwrite the existing stubbed-out file. You can perform the upload using ath S3 console, or the commandline. Refresh the TravelBuddy web page and check the developer console to confirm there are no errors following the changes you have made. "
},
{
	"uri": "/1-prerequisites/1-create-environment/1-vpc/",
	"title": "VPC",
	"tags": [],
	"description": "",
	"content": "VPC CloudFormation template định nghĩa một VPC gọi là DevAxNetworkLabVPC chứa 4 mạng con (network subnet) - 2 công khai (các máy ảo được gán với mạng con này có thể được truy cập trực tiếp từ internet) và 2 riêng tư (các mảy ảo được gán với mạng con nào sử dụng private IP và không thể được truy cập trực tiếp từ internet)\nTrong AWS Console, mở VPC Trong bảng điều khiển VPC, chọn Your VPCs, ta thấy một VPC được tạo có tên CdkStack/DevAxNetworkLabVPC. VPC\nChọn Subnets và Filter với VPC CdkStack/LabVPC bạn sẽ thấy 4 subnets - 2 private và 2 public. Bài thực hành này sử dụng 2 Availibility Zones (AZs), mỗi AZs có một public và một private subnet. CloudFormation template cũng định nghĩa một Network Address Translation gateway (NAT gateway) thực hiện ánh xạ giữa địa chỉ IP nội bộ của các máy chủ định tuyến qua nó và địa chỉ IP bên ngoài, để các máy ảo dù có private IP nhưng vẫn có thể truy xuất dữ liệu từ Internet. 4. Chọn NAT Gateways. Bạn sẽ thấy 2 NAT gateways, mỗi gateway cho một private subnet truy cập internet và các dịch vụ khác của AWS nhưng ngăn các dịch vụ bên ngoài truy cập trực tiếp với các tài nguyên bên trong các private subnet\n"
},
{
	"uri": "/2-spa/1-prerequisites/b/",
	"title": "AWS Cloud9 Environment",
	"tags": [],
	"description": "",
	"content": "Cloud Based Integrated Development Environment with AWS Cloud9 In this module we will be using AWS Cloud9. WS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don’t need to install files or configure your development machine to start new projects. Since your Cloud9 IDE is cloud-based, you can work on your projects from your office, home, or anywhere using an internet-connected machine. Cloud9 also provides a seamless experience for developing serverless applications enabling you to easily define resources, debug, and switch between local and remote execution of serverless applications. With Cloud9, you can quickly share your development environment with your team, enabling you to pair program and track each other’s inputs in real time.\nContents\nCloud Based Integrated Development Environment with AWS Cloud9 Install the SAM CLI Install maven DynamoDB Setup Using Search box - type in cloud9 and choose Cloud9 service. Then click Create environment. This will bring up a new screen, enter Your name in the name field and click Next Step.\nFor Environment type, choose Create a new EC2 Instance for environment (direct access)\nFor Instance type, choose a t3.small\nFor Platform, choose Amazon Linux 2\nUnder VPC chose the DevAxNetworkVPC (remember, you can find the VPC ID in the AWS Console under VPC) and choose the same subnet as the DevAxWindowsHost in the ec2 instance menu. Click Next step.\nReview your settings and click Create environment.\nThis will take a few minutes to start up,\nand you should get redirected to the AWS Cloud9 screen.\rStart having a look around the Cloud9 environment, notice you have a console you can use to do your work from, and there are debugging and lambda setup on the right side. See what other lambda functions are already in the AWS account and review them. Double click on the CreateGitCredsFunction and import it into your environment. Notice anything in the IDE? We now need to setup the required **JAVA version to be 1.8** and change the required parameters on the IDE. We will be using Amazon Corretto, a no-cost, multiplatform, production-ready distribution of OpenJDK. Corretto comes with long-term support that will include performance enhancements and security fixes.\rIn the Cloud9 terminal window, install Amazon Corretto 8 by issuing the following commands: sudo amazon-linux-extras enable corretto8 sudo yum install -y java-1.8.0-amazon-corretto-devel In the Cloud9 terminal window, verify that the right Java version is installed (at the time of writing this was 1.8.0_265): java -version You should see output similar to the following:\nAdmin:~/environment $ openjdk version \u0026#34;1.8.0_265\u0026#34; OpenJDK Runtime Environment Corretto-8.265.01.1 (build 1.8.0_265-b01) OpenJDK 64-Bit Server VM Corretto-8.265.01.1 (build 25.265-b01, mixed mode) Install the SAM CLI We will install the AWS Serverless Application Model (SAM) Cli to our AWS Cloud9 environment. The AWS Serverless Application Model (SAM) is an open-source framework for building serverless applications. It provides shorthand syntax to express functions, APIs, databases, and event source mappings. With just a few lines per resource, you can define the application you want and model it using YAML. During deployment, SAM transforms and expands the SAM syntax into AWS CloudFormation syntax, enabling you to build serverless applications faster.\nIn the Cloud9 terminal window, install the SAM CLI by issuing the following command: sudo pip3 install --upgrade aws-sam-cli Install maven We will use Apache Maven to manage project build and dependancy management for our project.\nTo install Apache Maven in the Cloud9 terminal window, issue the following commands: sudo wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo sudo sed -i s/\\$releasever/6/g /etc/yum.repos.d/epel-apache-maven.repo sudo yum install -y apache-maven Unfortunately the maven installer switches our JDK to 1.7 so we need to switch back to 1.8.9.\nTo switch our JDK to Corretto 8, issue the following commands in the Cloud9 terminal: sudo alternatives --config java #enter the number for corretto 8 sudo alternatives --config javac #enter the number for corretto 8 You should see something similar to the following:\nDynamoDB Setup We need to populate a DynamoDB table with information that will be used during the lab. This information will be used to calculate trips between different cities.\nDownload the following file to your AWS Cloud9 terminal: populate_tripsector.sh DB file\rpopulate_tripsector.sh\r(1 ko)\rExecute the following in your AWS Cloud9 terminal. bash populate_tripsector.sh \u0026lt;AWS_REGION\u0026gt; Open the DynamoDB service in the console and check the table TravelBuddyTripSectors table and confirm there are 50 rows in the table. "
},
{
	"uri": "/2-spa/4-codestar-cicd/b/",
	"title": "AWS Cloud9 Environment",
	"tags": [],
	"description": "",
	"content": "The next microservice we need for our TravelBuddy serverless application is the FlightSpecials API. We have seen FlightSpecials before in this course, so it should be familiar to you. It functions the same way as the HotelSpecials API in that it must be deployed with VPC integration so it can connect to the MySQL database to query for data. Instead of manually packaging and deploying this microservice, we will use CodeStar to build out a full CI/CD pipeline for us, as we have done in previous labs. So, since you have created CI/CD pipelines using AWS CodeStar a few times now, we are not going to provide you with full step-by-step instructions. If you need help, ask a Lab Assistant how to complete the tasks required to create a new CodeStar project and deploy the FlightSpecials code over the sample application provided by CodeStar.\nContents\nCreate a CI/CD pipeline with AWS CodeStar Update placeholder parameters in the CloudFormation template Update the target AWS region in the swagger.yml API definition file Create CodeStar Project AWS Cloud9 setup codecommit Check changes into source control to trigger a deploy Test the FlightSpecials API Create a CI/CD pipeline with AWS CodeStar Create a new AWS CodeStar Web Service project targeting Java on AWS Lambda. Call the project FlightSpecialsAPI. If you need help with this task, see the CodeStar documentation. Create the CodeStar project from your Cloud9 IDE. See the documentation. Remember to add the git config helpers setup as below: cd ~/environment aws codestar create-project --generate-cli-skeleton | tee template.yml This will create a template.yml file with the base skeleton. It requires details the following details to be updated. You can think of this as an overlay to create your CodeStar project, which will use the toolchain and zip file for your creation of the codestar project\nS3 bucket name and key: This is the details for codestar deployment on where to grab the build for the pipeline. Destination: This is the name of the codecommit repository or github repository, we are only using codecommit, but you can adapt this if you need to grab from your github repo. Toolchain: this is a cloudformation template which sets up the required toolchain elements. It is the same as what has been done for you in eclipse, and will will create the following resources. CodeCommit - s3bucket and policies to store the artifact CodeCommit event - codecommit change occurs to action a new build CodeBuild project - to build based off of the buildspec.yml CodePipeline - project pipeline which will action all the required phases Download and open the toolchain.yml file found here: toolchain.yml We need to change the details for the toolchain.yml file to point to the correct docker container to be used. The docker container has all the pre-built requirements based on different requirements. In this website look for the one which will suit our JAVA 1.8, maven requirements. https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-available.html\nIn the toolchain.yml look for the current container which will look as follows:\nCodeBuildProject: DependsOn: - CodeBuildPolicy Properties: Artifacts: Packaging: zip Type: codepipeline Cache: Type: S3 Location: !Sub \u0026#39;${S3Bucket}/codebuildcache\u0026#39; Description: !Sub \u0026#34;AWS CodeStar created CodeBuild Project for ${ProjectId}\u0026#34; Environment: ComputeType: small # This environment variable informs AWS CodeBuild where it can retrieve your code artifact. # You can specify any other environment variables your buildspec.yml is looking for. EnvironmentVariables: - Name: S3_BUCKET Value: !Ref \u0026#39;S3Bucket\u0026#39; # Replace this Docker image if necessary: https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-available.html Image: aws/codebuild/eb-nodejs-6.10.0-amazonlinux-64:4.0.0 Type: LINUX_CONTAINER Change the image to be the version you need for java. aws codebuild list-curated-environment-images You could do this by also querying the json payload: aws codebuild list-curated-environment-images --query \u0026#34;platforms[].languages[?language==\u0026#39;JAVA\u0026#39;].images\u0026#34; Replace the latest one in the toolchain.yml: Image:aws/codebuild/eb-java-8-amazonlinux-64:2.4.3-1.0.0 Remember to change these as newer versions are released to make sure you are using the latest.\nThe other part to review is how the cache and the buildspec works. Notice the cache component:\nCache: Type: S3 Location: !Sub \u0026#39;${S3Bucket}/codebuildcache\u0026#39; This is setup to an S3 bucket, which is used in the setup for the buildspec.yml file - which is shown below:\ncache: paths: - \u0026#39;/root/.m2/**/*\u0026#39; You need to also provide the required service role to the template.yml you created. To get examples of this you can do the following: aws codestar create-project help # check the examples to get the service role : \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::123456789012:role/service-role/aws-codestar-service-role\u0026#34; Get the FlightSpecials.zip file and download it into your cloud9 environment, and unzip it. FlightSpecials FlightSpecials source code\rFlightSpecials.zip\r(18 ko)\rUpdate placeholder parameters in the CloudFormation template Edit the FlightSpecials/template_cloud9.yml and update the required parameters If you are using eclipse you will need to have the CodeDeployRole as part of the parameters.\nItem to replace Description First network subnet for the mySQL database Second network subnet for the mySQL database The security group for the mySQL database The mySQL database endpoint When you’ve completed updating the values, the VPCConfig section will look similar to this (with different values):\nVpcConfig: SecurityGroupIds: - sg-858e61e3 SubnetIds: - subnet-3c989d4a - subnet-a04255c4 Environment: Variables: JDBC_CONNECTION_STRING: jdbc:mysql://qlxx5jzrxxxby.cig0rzmdedgf.ap-northeast-1.rds.amazonaws.com:3306/travelbuddy?useSSL=false\u0026amp;serverTimezone=UTC\u0026amp;autoReconnect=true JDBC_UID: root JDBC_PWD: labpassword Update the target AWS region in the swagger.yml API definition file The swagger.yml file provided in the zip bundle is the definition for the API that exposes the microservice via Amazon API Gateway. It needs to be updated with details of your lab AWS Account Id and target AWS Region before you can deploy your microservice.\nIn the Cloud9 IDE, locate the swagger.yml file and open it in the text editor Search for the text REPLACE_AWS_REGION and replace it with the region you are using (for example, ap-northeast-1) Search for the text REPLACE_AWS_ACCOUNTID and replace it with the your AWS Account Id. You can find your AWS Account Id in the lab dashboard. Save the file. When bundling the zip file to be used in codedeploy, you need to bundle from the source directory. To do this run the following: cd ~/environment/FlightSpecials zip -r ../FlightSpecials.zip * Rezip the FlightSpecials.zip file with these updates. cd ~/environment rm FlightSpecials.zip cd FlightSpecials zip -r FlightSpecials.zip * adding: buildspec.yml (deflated 53%) adding: copy_files.sh (deflated 63%) adding: pom.xml (deflated 75%) adding: src/ (stored 0%) adding: src/test/ (stored 0%) adding: src/test/java/ (stored 0%) adding: src/test/java/devlounge/ (stored 0%) adding: src/test/java/devlounge/lambda/ (stored 0%) adding: src/test/java/devlounge/lambda/test/ (stored 0%) adding: src/test/java/devlounge/lambda/test/TestContext.java (deflated 76%) adding: src/test/java/devlounge/lambda/test/TestUtils.java (deflated 79%) adding: src/test/java/devlounge/lambda/test/LambdaFunctionHandlerTest.java (deflated 57%) adding: src/main/ (stored 0%) adding: src/main/java/ (stored 0%) adding: src/main/java/devlounge/ (stored 0%) adding: src/main/java/devlounge/model/ (stored 0%) adding: src/main/java/devlounge/model/FlightSpecial.java (deflated 73%) adding: src/main/java/devlounge/model/LambdaResult.java (deflated 62%) adding: src/main/java/devlounge/lambda/ (stored 0%) adding: src/main/java/devlounge/lambda/FlightSpecialsHandler.java (deflated 65%) adding: swagger.yml (deflated 68%) adding: template-configuration.json (deflated 18%) adding: template.yml (deflated 65%) Note that the directory FlightSpecials is now omitted which is very important to only have the actual code there that is required.\nNote the directory structure here is REALLY important : https://docs.aws.amazon.com/codebuild/latest/userguide/getting-started-cli-upload-source-code.html\nCreate CodeStar Project Copy the code over to the FlightSpecials. Your lab bucket will look something like this mod-9c10d0af24f74a4a-s3bucketlambdacode-vsuckr33vysr aws s3 cp FlightSpecials.zip s3://\u0026lt;Lambdabucket\u0026gt; Copy the toolchain.yml to the Lamdba bucket aws s3 cp toolchain.yml s3://\u0026lt;Lambdabucket\u0026gt; Create the codepipeline template for flightspecials, which will look like this: Change the XXX with your account details below for this to work.\n{ \u0026#34;name\u0026#34;: \u0026#34;flightspecials\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;flightspecials\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;flight specials java8 example using ci/cd\u0026#34;, \u0026#34;sourceCode\u0026#34;: [ { \u0026#34;source\u0026#34;: { \u0026#34;s3\u0026#34;: { \u0026#34;bucketName\u0026#34;: \u0026#34;\u0026lt;Lambdabucket\u0026gt;\u0026#34;, \u0026#34;bucketKey\u0026#34;: \u0026#34;FlightSpecials.zip\u0026#34; } }, \u0026#34;destination\u0026#34;: { \u0026#34;codeCommit\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;flightspecials\u0026#34; } } } ], \u0026#34;toolchain\u0026#34;: { \u0026#34;source\u0026#34;: { \u0026#34;s3\u0026#34;: { \u0026#34;bucketName\u0026#34;: \u0026#34;\u0026lt;Lambdabucket\u0026gt;\u0026#34;, \u0026#34;bucketKey\u0026#34;: \u0026#34;toolchain.yml\u0026#34; } }, \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::XXX:role/service-role/aws-codestar-service-role\u0026#34;, \u0026#34;stackParameters\u0026#34;: { \u0026#34;ProjectId\u0026#34;: \u0026#34;flightspecials\u0026#34; } } } Create the AWS Codestar project: aws codestar create-project --cli-input-json file://template.json { \u0026#34;arn\u0026#34;: \u0026#34;arn:aws:codestar:ap-northeast-1:436753246579:project/flightspecials\u0026#34; } Now check the cloudformation has completed, the codecommit has created a repo, and the first build has been kicked off.\nIf any of these fail, look at the errors. You will need to remove the created s3 buckets and recreate if there are any issues. If you are changing any code for FlightSpecials.zip remember to resend this to the lambda bucket, and not just on the filesystem.\nTo see if all worked : aws codestar describe-project --id flightspecials\nAWS Cloud9 setup codecommit Once you have created this, you need to setup your required git repo for codecommit you configured previously.\nMove the original zip file, as this was just for the first upload, then setup required helper class and clone your repository. mv FlightSpecials FlightSpecials_orig git config --global credential.helper \u0026#39;!aws codecommit credential-helper $@\u0026#39; git config --global credential.UseHttpPath true git clone https://git-codecommit.ap-northeast-1.amazonaws.com/v1/repos/flightspecials cd flightspecials Give CloudFormation permission to create an IAM role\nAs part of our microservice setup, we will be assigning a new IAM Role to our Lambda function to allow it to perform various tasks. When CodeStar created our project, it created an IAM Role that gave CloudFormation just enough permissions to deploy the Hello World example service. These permissions are not enough for our more advanced requirements. So we need to adjust the policies assigned to the CloudFormation role, to extend those permissions.\nOpen the AWS IAM Console in the browser. Click Roles on the navigation pane. In the Filter box, type CodeStarWorker-flightspecialsa-CloudFormation to locate the correct IAM Role. If you can\u0026rsquo;t find the role, it may be too early - CodeStar may still be provisioning the pipeline and may not yet have created the role. Check the progress of the provisioning in the CodeStar dashboard.\nClick on the role to open the details panel. Click Attach Policy, in the Filter box, type idevelop to shortlist the available policies. Select the idevelopCodeStarCloudFormationPolicy policy shown in the list. This policy has been created for you by the lab setup process, and has the permissions assigned to it to allow CloudFormation to work on our behalf when creating the Lambda execution role. Select the listed policy and click Attach Policy Check changes into source control to trigger a deploy Now that you have completed updating files, you need to add the changed files to your new-implementation git branch and commit the files. You can use the commandline in your Cloud9 IDE: Issue git status to review the changed code files Issue git add . to add in the changed files Issue git commit -m \u0026quot;Baseline implementation\u0026quot; to commit the changes and provide a message Issue git checkout master to switch back to the master branch Now merge the changes for your new implementation into the master branch by issuing git merge new-implementation Issue git push to push the changes to CodeCommit. It will take a few moments to push the code and commence the deployment. Checking in the source code and templates will trigger the pipeline to build and deploy the new implementation. AWS CodePipeline will now use CloudFormation to deploy the following resources:\nWhile you have some time, spend a few minutes to explore the buildspec.yml, swagger.yml and template.yml files which define the Amazon API Gateway, AWS Lambda function and the build/deployment process through AWS CodeBuild. You will notice that the builspec.yml file uses the same AWS CLI command to package the deployment that you used when you manually packaged the HotelSpecials API earlier\nDo not execute these commands below, they are here as a reference!\nmvn package shade:shade aws cloudformation package --template template.yml --s3-bucket $S3_BUCKET --output-template template-export.yml The template.yml file uses the Serverless Application Model (SAM) transform to define the REST API, as opposed to how we approached this in the HotelSpecials API example. In HotelSpecials, the CloudFormation template used canonical CloudFormation to define the REST API so that it could be explicit about the API definition and include the swagger definition inline. The FlightSpecials example uses a more declarative approach and left the details to SAM. You are free to mix CloudFormation and SAM in the same template, as you can see from these examples.\nNote that the $S3_BUCKET environment variable is automatically replaced by CodeBuild when the build step is performed, and replaced by the S3 Bucket that CodeStar provisioned when it set up the project.\nTest the FlightSpecials API You can check the status of the deployment of the code change through the pipeline back on the CodeStar project dashboard. Once the deployment has completed through the CI/CD pipeline, you are ready to test the API.\nOpen the API Gateway console in the browser and under APIs, click the iDevelop - Flight Specials API link to reveal the resources for the API. Click on the Stages link beneath the iDevelop - Flight Specials API. Expand the prod root element in the Stages list to reveal the hierarchy. Click on the GET method Click on the Invoke URL value in the prod - GET - /flightspecials panel. After a moment while the Lambda function is initialised, you should see the JSON result of querying the mySQL database from the Lambda function. For example: { \u0026#34;succeeded\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;errorCode\u0026#34;: 0, \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;header\u0026#34;: \u0026#34;London to Prague\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Jewel of the East\u0026#34;, \u0026#34;cost\u0026#34;: 93, \u0026#34;expiryDate\u0026#34;: 1504072439813 }, { \u0026#34;id\u0026#34;: 2, \u0026#34;header\u0026#34;: \u0026#34;Paris to London\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Weekend getaway!\u0026#34;, \u0026#34;cost\u0026#34;: 182, \u0026#34;expiryDate\u0026#34;: 1504074888702 } ] } If you see a JSON payload with no errors, you have successfully deployed an API and supporting Lambda function that queries the mySQL database. Notice how much quicker and easier that was to deploy without any manual intervention, and you didn\u0026rsquo;t even have to interact with the AWS CLI or Console? Everything was driven by the source control check-in process.\nYou are now ready to integrate these APIs with the TravelBuddy web site.\n"
},
{
	"uri": "/3-aaa/2-microservice-authen/",
	"title": "Microservice Authentication",
	"tags": [],
	"description": "",
	"content": "Setting up Authentication for the Microservice\nRight now, if you click the Go! button on the web site and do not enter a city to filter, you will see a dialog with all available trips. We want to change this behaviour so that you must be logged in in order to be able to search for all trips without a filter. This is just an example to demonstrate how we could limit certain API calls to only authenticated users.\nContents\nUpdate the AWS API Gateway Create an Authorizer that uses the Cognito User Pool Mark the /trips microservices to require authentication Update the AWS API Gateway Open the AWS API Gateway console, and click on the Gateway Responses link beneath the iDevelop - Trip Search API link. In the Gateway Responses panel, scroll down to locate the Unauthorized (401) panel and open it. Click Edit In order for our web application to be able to receive the unauthorized 401 status, we need to add CORS headers to the response. Without the headers, the browser will not have permission to receive the 401 status. We have already enabled CORS for status 200 responses when we set up the API Gateway endpoints earlier. But we need to explicitly allow for status 401 to be returned. In the Response Headers section, add in the following two header/value pairs:\nHeader name \u0026lsquo;static value\u0026rsquo; Access-Control-Allow-Origin \u0026lsquo;*\u0026rsquo; Access-Control-Allow-Headers \u0026lsquo;*\u0026rsquo; You must provide the single-quotes around the static value as shown above. Don\u0026rsquo;t provide * by itself, surround it with single-quotes like shown. Make sure that there is no trailing space after the header name if you copy/pasted from the lab cloudformation values.\nClick the Save button in the 401 panel to commit the changes. Create an Authorizer that uses the Cognito User Pool API Gateway integrates tightly with Cognito for authorization. You simply need to declare your Cognito User Pool as an authorizer for your API.\nClick the Authorizers link beneath the iDevelop - Trip Search API link on the left navigation panel Click Create New Authorizer For Name type TravelBuddy For Type select Cognito Select the TravelBuddy entry from the drop-down list for Cognito User Pool by first clicking inside the text entry field. For Token Source type Authorization and note that spelling and capitalization are important. Click Create Mark the /trips microservices to require authentication Click the Resources link beneath the iDevelop - Trip Search API link on the left navigation panel Click the GET method beneath /trips Click Method Request Click the pencil icon next to the Authorization field and from the menu that appears, select TravelBuddy. This is the authoriser we created in the previous step, and links to the Cognito User Pool we are using for our user database. If it does not appear, try refreshing your browser. Click the grey tick next to the field to save the change. "
},
{
	"uri": "/2-spa/2-build-deploy/",
	"title": "Serverless Microservices",
	"tags": [],
	"description": "",
	"content": "Manually Build and Deploy a Serverless Microservice\nIn this exercise, you will manually create and configure a serverless microservice. As you progress through this lab, you will use other techniques for build and deployment, so that you can compare and contrast the efficiencies of each approach and how automation makes the development experience more agile and increases developer efficiency.\nYou will create the TripSearch microservice manually. The TripSearch microservice exposes the following functions:\n/trips - returns a list of all available trips in the system /tripsfromcity - returns a list of all trips that originate from a given city /tripstocity - returns a list of all trips that have the given city as a destination This is the same microservice we looked at in a previous lab. But this time, we will expose this functionality in our TravelBuddy website, and so need to deploy the service to be available to the website. Previously, the API Gateway configuration was taken care of for you by the deployment pipeline - in this exercise, you will manually configure the setup of both the Lambda function and the API Gateway.\nContents\nDownload source code and build the deployment artefact Why am I seeing the message AWS X-ray unavailable - ignoring in the output? Create two new Lambda functions using the same deployment artefact Download source code and build the deployment artefact The lab setup has created an S3 bucket for you to store the deployment artefact for the Lambda function for the TripSearch microservice. First, you need to test and build the deployment package.\nDownload the source code bundle from TripSearchFull.zip and explode the zip file onto your filesystem. You can do this in your own operating system, the windows system or cloud9 as your options. The following command will download the bundle for you: curl -L http://workshops.devax.academy/monoliths-to-microservices/module6/files/TripSearchFull.zip --output TripSearchFull.zip Or download below:\nSource code bundle\rTripSearchFull.zip\r(21 ko)\rcd into the filesystem location where you exploded the TripSearchFull source code, and run the unit test by issuing one of the following commands: For MacOS:\nexport DDB_TABLENAME_TRIPSECTOR=TravelBuddyTripSectors; mvn test For Windows:\nset DDB_TABLENAME_TRIPSECTOR=TravelBuddyTripSectors mvn test For Cloud9 - if not already setup:\nset DDB_TAB sudo yum install -y java-1.8.0-openjdk-devel sudo alternatives --config java #enter 1.8 version #enter 2 sudo alternatives --config javac #enter 1.8 version #enter 2 sudo yum remove -y java-1.7.0-openjdk-devel sudo wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo sudo sed -i s/\\$releasever/6/g /etc/yum.repos.d/epel-apache-maven.repo sudo yum install -y apache-maven Run test for Cloud9:\nexport DDB_TABLENAME_TRIPSECTOR=TravelBuddyTripSectors; mvn test If the tests fail, First try to export you profile as the default profile e.g. On Windows: set AWS_PROFILE=devaxacademy | On Mac: export AWS_PROFILE=devaxacademy\nIf the tests continue to fail, it may be because the lab environment hasn’t yet finished creating. Check that the Lab is fully running before continuing.\nIf the tests fail and the first error message is \u0026ldquo;Unable to load AWS credentials from any provider in the chain\u0026rdquo;. Make sure to set your AWS CLI credentials.\nThis command sets the table name for the DynamoDB table to match the name of the table set by the lab setup. You will see output like the following:\n2021-03-30 18:03:55 \u0026lt;\u0026gt; WARN BasicProfileConfigLoader:96 - The legacy profile format requires the \u0026#39;profile \u0026#39; prefix before the profile name. The latest code does not require such prefix, and will consider it as part of the profile name. Please remove the prefix if you are seeing this warning. EnvVar DDB_TABLENAME_TRIPSECTOR detected - overriding DDB TableName to TravelBuddyTripSectors AWS X-ray unavailable - ignoring Found 52 total trips. Sun Jun 20 23:52:23 UTC 2021 \u0026gt; Melbourne to Geelong on Qantas Tue Jun 15 02:12:51 UTC 2021 \u0026gt; Geelong to Brisbane on Qantas Tue Aug 17 20:29:29 UTC 2021 \u0026gt; Melbourne to Cairo on Qantas Sat Mar 12 23:18:51 UTC 2022 \u0026gt; Sydney to Singapore on Qantas Thu May 27 02:55:51 UTC 2021 \u0026gt; Perth to Hobart on Qantas .....\u0026lt;omitted\u0026gt; Starting devlounge.lambda.FindTripsFromCityHandler Lambda with input Melbourne AWS X-ray unavailable - ignoring Found 8 total trips. Sun Jun 20 23:52:23 UTC 2021 \u0026gt; Melbourne to Geelong on Qantas Tue Aug 17 20:29:29 UTC 2021 \u0026gt; Melbourne to Cairo on Qantas Tue Jun 08 04:55:44 UTC 2021 \u0026gt; Melbourne to Dallas on Qantas Thu Dec 09 22:15:45 UTC 2021 \u0026gt; Melbourne to Singapore on Qantas Tue Jun 15 06:55:59 UTC 2021 \u0026gt; Melbourne to Broome on Qantas Sun Dec 19 18:06:06 UTC 2021 \u0026gt; Melbourne to Geelong on Qantas Fri Apr 09 05:45:41 UTC 2021 \u0026gt; Melbourne to Newcastle on Qantas Sun Apr 03 15:19:34 UTC 2022 \u0026gt; Melbourne to Sydney on Qantas Starting devlounge.lambda.FindTripsToCityHandler Lambda with city Sydney AWS X-ray unavailable - ignoring Found 2 total trips. Mon Feb 28 19:39:13 UTC 2022 \u0026gt; Perth to Sydney on Qantas Sun Apr 03 15:19:34 UTC 2022 \u0026gt; Melbourne to Sydney on Qantas Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.111 sec Results : Tests run: 1, Failures: 0, Errors: 0, Skipped: 0 Note that the from and to city examples shown here, and the dates and times, will be different for your environment because they have been randomly generated.\nYou should see no errors emitted by the unit test, which confirms the source code is building and running as expected. If you see an error, investigate.\nWhy am I seeing the message AWS X-ray unavailable - ignoring in the output? When you run the tests on your local development environment, the AWS X-ray agent is not available, and so the calls through the AWS SDK cannot be recorded with AWS X-ray. However, since the pom.xml file defines a dependency to the AWS X-ray recorder, all calls through the SDK (for example, to DynamoDB) are attempted to be recorded. This would normally cause an error, and the tests would fail.\nNotice that each of the Lambda handler classes extend a base class called LambdaHandlerWithXRayBase? In this class, there is a static initializer, and it builds ContextMissingStrategy object, overrides the behaviour for when there is no AWS X-ray context, and sets this as the default behaviour. In the implementation of the contextMissing handler, we simply print a message to the console, rather than the default action, which is to throw an exception. The implementation of the LambdaHandlerWithXRayBase class looks like this:\npublic class LambdaHandlerWithXRayBase { static { AWSXRayRecorderBuilder builder = AWSXRayRecorderBuilder.standard(); builder.withContextMissingStrategy(new ContextMissingStrategy() {\t@Override public void contextMissing(String arg0, Class\u0026lt;? extends RuntimeException\u0026gt; arg1) { System.out.println(\u0026#34;AWS X-ray unavailable - ignoring\u0026#34;); }\t}); AWSXRay.setGlobalRecorder(builder.build()); } } As an optional experiment, you could try removing the static initializer from the LambdaHandlerWithXRayBase base class, and re-running the Maven build. You will see errors such as:\ncom.amazonaws.xray.exceptions.SegmentNotFoundException: Thread failed to begin a subsegment: segment not found. Verify that a segment is in progress, and that the SegmentContextResolverChain is configured correctly in order to discover the segment. Without the agent being present, and the call to the Lambda function having the correct correlation Id context passed to it, the SegmentContextResolverChain cannot determine the AWS X-ray segment to attach the recorded metadata to, and throws an exception. The implementation we provide in the base class overrides this behaviour, to safely ignore this condition while testing on your development environment.\nIf the unit test run is succeeding, you are ready to build the deployment artefact. From the command line, issue the following: mvn package shade:shade The deployment artefact (JAR file) will be built and stored in ./target/tripsearch-1.0.0.jar In order to create an AWS Lambda function from this JAR file, you need to push the build artefact up to the S3BucketLambdaCode S3 bucket that is accessible by the AWS Lambda environment in the same region the Lambda function will be created in. Execute the following command after replacing the relevant parameters noted below:\naws s3 cp target/tripsearch-1.0.0.jar s3://\u0026lt;S3BucketLambdaCode\u0026gt; --region ap-northeast-1 Replace the with the value shown in Cloudformation Outputs tab for the key S3BucketLambdaCodeBucketName. Do not include the *\u0026lt;** and *\u0026gt;** symbols.\nCreate a new Lambda function from this deployment artefact, by issuing the following command after replacing the relevant parameters noted below: aws lambda create-function --function-name idevelopTripSearchFull --runtime java8 --role \u0026lt;LambdaRole\u0026gt; --handler devlounge.lambda.FindAllTripsHandler --code S3Bucket=\u0026lt;S3BucketLambdaCode\u0026gt;,S3Key=tripsearch-1.0.0.jar --timeout 15 --description \u0026#34;TravelBuddy TripSearch microservice - FindAllTrips\u0026#34; --memory-size 1024 --region ap-northeast-1 Replace the with the value shown in Cloudformation Outputs tab for the key S3BucketLambdaCodeBucketName. Replace the with the value shown in Cloudformation Outputs tab for the key LambdaRoleARN.\nDo not include the \u0026lt; and \u0026gt; symbols.\nIf successful, your new Lambda function will be created and you will see an output similar to the following:\n{ \u0026#34;FunctionName\u0026#34;: \u0026#34;idevelopTripSearchFull\u0026#34;, \u0026#34;FunctionArn\u0026#34;: \u0026#34;arn:aws:lambda:ap-northeast-1:XXXXXXXXXXXX:function:idevelopTripSearchFull\u0026#34;, \u0026#34;Runtime\u0026#34;: \u0026#34;java8\u0026#34;, \u0026#34;Role\u0026#34;: \u0026#34;arn:aws:iam::XXXXXXXXXXXX:role/LambdaRole\u0026#34;, \u0026#34;Handler\u0026#34;: \u0026#34;devlounge.lambda.FindAllTripsHandler\u0026#34;, \u0026#34;CodeSize\u0026#34;: 9737054, \u0026#34;Description\u0026#34;: \u0026#34;TravelBuddy TripSearch microservice - FindAllTrips\u0026#34;, \u0026#34;Timeout\u0026#34;: 15, \u0026#34;MemorySize\u0026#34;: 1024, \u0026#34;LastModified\u0026#34;: \u0026#34;2021-03-30T18:10:38.011+0000\u0026#34;, \u0026#34;CodeSha256\u0026#34;: \u0026#34;EGhfTqT/kThg05Ibn8ivLWcKSabLZtIh/t3brnmvyHA=\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;$LATEST\u0026#34;, \u0026#34;TracingConfig\u0026#34;: { \u0026#34;Mode\u0026#34;: \u0026#34;PassThrough\u0026#34; }, \u0026#34;RevisionId\u0026#34;: \u0026#34;4fdee380-f0ce-4e1e-ab1e-d42e74e89308\u0026#34;, \u0026#34;State\u0026#34;: \u0026#34;Active\u0026#34;, \u0026#34;LastUpdateStatus\u0026#34;: \u0026#34;Successful\u0026#34;, \u0026#34;PackageType\u0026#34;: \u0026#34;Zip\u0026#34; } Create two new Lambda functions using the same deployment artefact The code that implements our TripSearch function has three handlers exposed - one for finding all trips; one for finding trips that originate from a given city; and one for finding trips that have a given city as the destination. We have exposed only one handler so far - the search for all trips. In this section, we will create two new Lambda functions, each exposing one of the two remaining handlers.\nCreate a new Lambda function from the same deployment artefact we previously uploaded. We can create different Lambda functions from the same artefact because the artefact exports multiple Lambda handlers. In the step above, we exposed devlounge.lambda.FindAllTripsHandler. In this step we expose devlounge.lambda.FindTripsFromCityHandler. We simply need to issue the same command as above, but change the handler we are exposing and give the Lambda function a unique name. Issue the following command after replacing the relevant parameters noted below:\naws lambda create-function --function-name idevelopTripSearchFromCity --runtime java8 --role \u0026lt;LambdaRole\u0026gt; --handler devlounge.lambda.FindTripsFromCityHandler --code S3Bucket=\u0026lt;S3BucketLambdaCode\u0026gt;,S3Key=tripsearch-1.0.0.jar --timeout 15 --description \u0026#34;TravelBuddy TripSearch microservice - FindTripsFromCity\u0026#34; --memory-size 1024 --region ap-northeast-1 Replace the with the value shown in Cloudformation Outputs tab for the key S3BucketLambdaCodeBucketName. Replace the with the value shown in Cloudformation Outputs tab for the key LambdaRoleARN.\nConfirm that you receive a success response similar to the response when you successfully created the first Lambda function.\nCreate the last Lambda function from the same deployment artefact, this time for FindTripsToCity. As per the previous step, we are exposing an additional handler, this time devlounge.lambda.FindTripsToCityHandler. Issue the following command after replacing the relevant parameters noted below:\naws lambda create-function --function-name idevelopFindTripsToCity --runtime java8 --role \u0026lt;LambdaRole\u0026gt; --handler devlounge.lambda.FindTripsToCityHandler --code S3Bucket=\u0026lt;S3BucketLambdaCode\u0026gt;,S3Key=tripsearch-1.0.0.jar --timeout 15 --description \u0026#34;TravelBuddy TripSearch microservice - FindTripsToCity\u0026#34; --memory-size 1024 --region ap-northeast-1 Replace the with the value shown in Cloudformation Outputs tab for the key S3BucketLambdaCodeBucketName. Replace the with the value shown in Cloudformation Outputs tab for the key LambdaRoleARN.\nConfirm that you receive a success response similar to the response when you successfully created the Lambda function.\n"
},
{
	"uri": "/2-spa/",
	"title": "Single Page Application",
	"tags": [],
	"description": "",
	"content": "Creating A Single Page Application\nIn this exercise you will create the Single Page Application (SPA) website for TravelBuddy. A single-page application is a web application or website that interacts with the user by dynamically rewriting the current web page with new data from the web server, instead of the default method of the browser loading entire new pages. The SPA will interact with a set of APIs exposed by API Gateway.\nContents\nInstall \u0026amp; Configure Prerequisites Manually Build and Deploy a Serverless Microservice Create and Expose the API with Amazon API Gateway Deploy the API using CodeStar and CI/CD Setup the Single Page Application Website Build a Client to Consume the API "
},
{
	"uri": "/2-prepare/2.2-createstack/",
	"title": "Create a CloudFormation stack",
	"tags": [],
	"description": "",
	"content": "Create a CloudFormation stack Template File\rModule6.template.yaml\r(52 ko)\rDownload file Module6.template.yaml. Go to Amazon CloudFormation Console. Click Stacks Click Create stack. Click With new resources (standard). In the Specify template section. Select Upload a template file Click Choose file, then select file Module6.template.yaml we downloaded. Click Next. In the Stack name section, type DevAx-06. In the Stack name section, seclect KPforDevAxInstances. Click Next. In the Configure stack options page, Drag the screen down, then Click Next. In the Review page. Drag the screen down, then Click I acknowledge that AWS CloudFormation might create IAM resources with custom names. Click Create stack. Cloudformation will take 5 minutes to deploy Web App. Wait until all stacks are shown in a CREATE_COMPLETE state.\n"
},
{
	"uri": "/3-create-single-page-app/3.2-build-and-deploy-serverless-microservice/",
	"title": "Manually Build And Deploy A Serverless Microservice",
	"tags": [],
	"description": "",
	"content": "Manually Build And Deploy A Serverless Microservice In this exercise, you will manually create and configure a serverless microservice. As you progress through this lab, you will use other techniques for build and deployment, so that you can compare and contrast the efficiencies of each approach and how automation makes the development experience more agile and increases developer efficiency.\nYou will create the TripSearch microservice manually. The TripSearch microservice exposes the following functions:\n/trips - returns a list of all available trips in the system. /tripsfromcity - returns a list of all trips that originate from a given city /tripstocity - returns a list of all trips that have the given city as a destination This is the same microservice we looked at in a previous lab. But this time, we will expose this functionality in our TravelBuddy website, and so need to deploy the service to be available to the website. Previously, the API Gateway configuration was taken care of for you by the deployment pipeline - in this exercise, you will manually configure the setup of both the Lambda function and the API Gateway.\nDownload source code and build the deployment artefact TripSearchFull Project\rTripSearchFull.zip\r(21 ko)\rDownload TripSearchFull.zip file and extract Open Command Prompt and navigate to the directory of the TripSearchFull project was extracted in step 1 Execute the below command: set AWS_PROFILE=devaxacademy\rset DDB_TABLENAME_TRIPSECTOR=TravelBuddyTripSectors\rmvn test 3. You will see the following result: Note that the from and to city examples shown here, and the dates and times, will be different for your environment because they have been randomly generated.\nYou should see no errors emitted by the unit test, which confirms the source code is building and running as expected. If you see an error, investigate.\nWhy am I seeing the message AWS X-ray unavailable - ignoring in the output? When you run the tests on your local development environment, the AWS X-ray agent is not available, and so the calls through the AWS SDK cannot be recorded with AWS X-ray. However, since the pom.xml file defines a dependency to the AWS X-ray recorder, all calls through the SDK (for example, to DynamoDB) are attempted to be recorded. This would normally cause an error, and the tests would fail.\nNotice that each of the Lambda handler classes extend a base class called LambdaHandlerWithXRayBase? In this class, there is a static initializer, and it builds ContextMissingStrategy object, overrides the behaviour for when there is no AWS X-ray context, and sets this as the default behaviour. In the implementation of the contextMissing handler, we simply print a message to the console, rather than the default action, which is to throw an exception. The implementation of the LambdaHandlerWithXRayBase class looks like this:\npublic class LambdaHandlerWithXRayBase {\rstatic {\rAWSXRayRecorderBuilder builder = AWSXRayRecorderBuilder.standard();\rbuilder.withContextMissingStrategy(new ContextMissingStrategy() {\t@Override\rpublic void contextMissing(String arg0, Class\u0026lt;? extends RuntimeException\u0026gt; arg1) { System.out.println(\u0026#34;AWS X-ray unavailable - ignoring\u0026#34;); }\t});\rAWSXRay.setGlobalRecorder(builder.build());\r}\r} As an optional experiment, you could try removing the static initializer from the LambdaHandlerWithXRayBase base class, and re-running the Maven build. You will see errors such as:\ncom.amazonaws.xray.exceptions.SegmentNotFoundException: Thread failed to begin a subsegment: segment not found. Verify that a segment is in progress, and that the SegmentContextResolverChain is configured correctly in order to discover the segment. Without the agent being present, and the call to the Lambda function having the correct correlation Id context passed to it, the SegmentContextResolverChain cannot determine the AWS X-ray segment to attach the recorded metadata to, and throws an exception. The implementation we provide in the base class overrides this behaviour, to safely ignore this condition while testing on your development environment.\nIf the unit test run is succeeding, Execute the command mvn package shade:shade to build It will take a few moments to complete the build. When the target JAR is built, whick is in the folder target of the project and whose name is tripsearch-1.0.0.jar Go to Amazon CloudFormation Console. Click Stacks Type DevAx-06 in the search bar and press Enter Click DevAx-06 Click tab Outputs Save the value LambdaRoleARN and S3BucketLambdaCodeBucketName to use in the next step In Command Prompt, execute the below command aws s3 cp target/tripsearch-1.0.0.jar s3://\u0026lt;S3BucketLambdaCodeBucketName\u0026gt; --region \u0026lt;YOUR_REGION\u0026gt; Replace \u0026lt;S3BucketLambdaCodeBucketName\u0026gt; by the value S3BucketLambdaCodeBucketName we saved in step 7\nReplace \u0026lt;YOUR_REGION\u0026gt; by your Region\n9. Execute the following command to create a new Lambda function from this deployment artefact\naws lambda create-function --function-name idevelopTripSearchFull --runtime java8 --role \u0026lt;LambdaRoleARN\u0026gt; --handler devlounge.lambda.FindAllTripsHandler --code S3Bucket=\u0026lt;S3BucketLambdaCodeBucketName\u0026gt;,S3Key=tripsearch-1.0.0.jar --timeout 15 --description \u0026#34;TravelBuddy TripSearch microservice - FindAllTrips\u0026#34; --memory-size 1024 --region \u0026lt;YOUR_REGION\u0026gt; Replace \u0026lt;LambdaRoleARN\u0026gt; by the value LambdaRoleARN we saved in step 7\nReplace \u0026lt;S3BucketLambdaCodeBucketName\u0026gt; by the value S3BucketLambdaCodeBucketName we saved in step 7\nReplace \u0026lt;YOUR_REGION\u0026gt; by your Region\n10. If successful, your new Lambda function will be created and you will see an output similar to the following: Create two new Lambda functions using the same deployment artefact The code that implements our TripSearch function has three handlers exposed - one for finding all trips; one for finding trips that originate from a given city; and one for finding trips that have a given city as the destination. We have exposed only one handler so far - the search for all trips. In this section, we will create two new Lambda functions, each exposing one of the two remaining handlers.\nCreate a new Lambda function from the same deployment artefact we previously uploaded. We can create different Lambda functions from the same artefact because the artefact exports multiple Lambda handlers. In the step above, we exposed devlounge.lambda.FindAllTripsHandler. In this step we expose devlounge.lambda.FindTripsFromCityHandler. Execute the following command: aws lambda create-function --function-name idevelopTripSearchFromCity --runtime java8 --role \u0026lt;LambdaRoleARN\u0026gt; --handler devlounge.lambda.FindTripsFromCityHandler --code S3Bucket=\u0026lt;S3BucketLambdaCodeBucketName\u0026gt;,S3Key=tripsearch-1.0.0.jar --timeout 15 --description \u0026#34;TravelBuddy TripSearch microservice - FindTripsFromCity\u0026#34; --memory-size 1024 --region \u0026lt;YOUR_REGION\u0026gt; Replace \u0026lt;LambdaRoleARN\u0026gt; by the value LambdaRoleARN we saved in step 7\nReplace \u0026lt;S3BucketLambdaCodeBucketName\u0026gt; by the value S3BucketLambdaCodeBucketName we saved in step 7\nReplace \u0026lt;YOUR_REGION\u0026gt; by your Region\n12. Create the last Lambda function from the same deployment artefact, this time for FindTripsToCity. As per the previous step, we are exposing an additional handler, this time devlounge.lambda.FindTripsToCityHandler. Execute the following command:\naws lambda create-function --function-name idevelopFindTripsToCity --runtime java8 --role \u0026lt;LambdaRoleARN\u0026gt; --handler devlounge.lambda.FindTripsToCityHandler --code S3Bucket=\u0026lt;S3BucketLambdaCodeBucketName\u0026gt;,S3Key=tripsearch-1.0.0.jar --timeout 15 --description \u0026#34;TravelBuddy TripSearch microservice - FindTripsToCity\u0026#34; --memory-size 1024 --region \u0026lt;YOUR_REGION\u0026gt; Replace \u0026lt;LambdaRoleARN\u0026gt; by the value LambdaRoleARN we saved in step 7\nReplace \u0026lt;S3BucketLambdaCodeBucketName\u0026gt; by the value S3BucketLambdaCodeBucketName we saved in step 7\nReplace \u0026lt;YOUR_REGION\u0026gt; by your Region\nConfirm that you receive a success response similar to the response when you successfully created the first Lambda function.\n"
},
{
	"uri": "/4-configure-aaa/4.2-setup-authentication/",
	"title": "Microservice Authentication",
	"tags": [],
	"description": "",
	"content": "Setting Up Authentication For The Microservice Right now, if you click the Go! button on the web site and do not enter a city to filter, you will see a dialog with all available trips. We want to change this behaviour so that you must be logged in in order to be able to search for all trips without a filter. This is just an example to demonstrate how we could limit certain API calls to only authenticated users.\nGo to AWS API Gateway Console. Type iDevelop - Trip Search API to the search bar Click iDevelop - Trip Search API Click Gateway Responses Select Unauthorized Click Edit In order for our web application to be able to receive the unauthorized 401 status, we need to add CORS headers to the response. Without the headers, the browser will not have permission to receive the 401 status. We have already enabled CORS for status 200 responses when we set up the API Gateway endpoints earlier. But we need to explicitly allow for status 401 to be returned. Click Add response header In the Response header column of the first Response Header, type Access-Control-Allow-Origin In the Value column, type '*' In the Response header column of the second Response Header, type Access-Control-Allow-Headers In the Value column, type '*' Click Save Create an Authorizer that uses the Cognito User Pool API Gateway integrates tightly with Cognito for authorization. You simply need to declare your Cognito User Pool as an authorizer for your API.\nClick Authorizers Click Create New Authorizer In the Name section, type TravelBuddy In the Type section, select Cognito In the Cognito User Pool section, select TravelBuddy In the Token Source section, type Authorization Click Create Mark the /trips microservices to require authentication Click Resources Click the GET method beneath /trips Click Method Request In the Authorization section, click the pencil icon Select TravelBuddy. This is the authoriser we created in the previous step, and links to the Cognito User Pool we are using for our user database. If it does not appear, try refreshing your browser. Click the grey tick next to the field to save the change. "
},
{
	"uri": "/2-prepare/",
	"title": "Preparation",
	"tags": [],
	"description": "",
	"content": "Overview In this section, we will create the Key Pair, create the CloudFormation stack and Connect to the Windows instance.\nContent: Create the Key Pair Create the CloudFormation stack Connect to the Windows instance "
},
{
	"uri": "/1-prerequisites/1-create-environment/2-ec2/",
	"title": "EC2",
	"tags": [],
	"description": "",
	"content": "EC2 CloudFormation cũng tạo một workspace instance.\nTruy cập vào bảng điều khiển EC2 Chọn Instances, bạn sẽ thấy một EC2 instance đã được tạo sẵn Nếu bạn không thấy bất kỳ instance nào trong danh sách, vui lòng kiểm tra bảng điều khiển AWS CloudFormation. Các mod-xxxxxx stack status, phải là CREATE_COMPLETE trước khi một EC2 instance chạy\nChọn tab Security, bạn sẽ thấy security group được gắn với máy ảo. Chọn mở rộng tab Inbound rules bạn sẽ thấy các giao thức cũng như địa chỉ IP nguồn được phép truy cập từ những port này. Trong bài thực hành này, CloudFormation template tạo các quy tắc bảo mật cho phép tất cả các địa chỉ IP nguồn được phép kết nối tới. Bạn có thể chỉnh sửa và chỉ cho phép kết nối tới từ địa chỉ IP của bạn.\nChọn tab Volumes, bạn sẽ thấy một EBS volume. "
},
{
	"uri": "/1-prerequisites/2-remote-env-config-cli/",
	"title": "Remote enviroment &amp; Configure the AWS CLI",
	"tags": [],
	"description": "",
	"content": "Remote into Windows instance Truy cập vào AWS EC2 và vào máy ảo DexAxWindowsHost Chọn Connect Chọn tab RDP client Chọn Getpassword để lấy mật khẩu đăng nhập vào máy ảo Chọn Browse và trỏ tới tập tin keypair đã lưu ở phần 1. Chọn Decrypt Password Sao chép mật khẩu và chọn Download remote desktop file. Một file RDP sẽ được tải xuống, dùng để truy cập vào máy ảo Windows Mở file RDP đã tải, nhập mật khẩu đã lưu ở bước 6 và chọn Connect. Một cảnh báo về xác minh chứng chỉ có thể xuất hiện, chọn Continue để tiếp tục. Như vậy, ta đã kết nối được vào máy ảo Windows được tạo.\nConfigure AWS CLI Mở và nhập đoạn sau vào trình soạn thảo aws configure set profile.devaxacademy.region \u0026lt;your_region\u0026gt; aws configure set profile.devaxacademy.aws_access_key_id \u0026lt;access_key_id\u0026gt; aws configure set profile.devaxacademy.aws_secret_access_key \u0026lt;secret_access_key\u0026gt; Nếu bạn đã có một bộ thông tin xác thực cho người dùng IAM có đặc quyền quản trị, bạn có thể sử dụng lại chúng cho các thông tin bên dưới trong bước tiếp theo. Nếu bạn chưa có thông tin xác thực truy cập, làm theo hướng dẫn tại đây để truy xuất chúng cho người dùng có đặc quyền quản trị để sử dụng trong bài thực hành này. Điền các giá trị của người dùng IAM vào câu lệnh aws configure: \u0026lt;your_region\u0026gt; với Region code \u0026lt;access_key_id\u0026gt; với giá trị Access Key Id \u0026lt;secret_access_key\u0026gt; với giá trị Secret Access Key Sao chép và dán đoạn code vào comand line và thực thi chúng "
},
{
	"uri": "/3-aaa/",
	"title": "Configure AAA",
	"tags": [],
	"description": "",
	"content": "Configure Authentication, Authorization and Accounting (AAA)\nRight now, our TravelBuddy SPA does not require any authentication in order to call the API services we have exposed. The lab setup process has provisioned a Cognito User Pool and a Cognito Identity Pool in your account. The Cognito User Pool is your fully-managed system of record for users in your application. The Identity Pool is used to obtain temporary AWS IAM credentials to sign requests that require SigV4 signing. The Cognito Identity Pool federates between multiple Identity Providers, but in our lab example, we only have one Identity Provider (the User Pool). Our TravelBuddy SPA does not actually have the requirement for IAM credentials, but we have implemented the feature to demonstrate how you can accomplish this. As a Challenge Exercise, we will ask you to implement AWS IAM Authorisation for a call into API Gateway, but this is an optional task for the lab.\nContents Add Authentication to the SPA using Amazon Cognito User Pools Setting up Authentication for the Microservice Deploy and Test the new Behaviour Add new User Sign Up and Sign In "
},
{
	"uri": "/2-spa/3-api-gateway/",
	"title": "Create and Expose the API",
	"tags": [],
	"description": "",
	"content": "Create and Expose the API with Amazon API Gateway\nNow that you have created the Lambda functions, it is time to manually create the API Gateway deployment that will expose the microservice as an API.\nContents\nExpose the /tripsfromcity RESTful API endpoint Expose the /tripstocity RESTful API endpoint Deploy the API and test Exercise 2 - Use CloudFormation/SAM via the AWS CLI to deploy the HotelSearch microservice Test the HotelSpecials API Open the AWS API Gateway console by clicking Services and typing api in the filter box. Press Enter. Click Get Started if shown. Go to create REST API and click Build. Make sure not to click the option with the word \u0026ldquo;Private\u0026rdquo;. If a new screen comes up, click OK. Make sure you have New API radio button selected: For API Name type iDevelop - Trip Search API For Description type Allows searching for trips from/to cities Click Create API. The API will be created, and have a root path element and nothing else. Click on the / root path element and then click Actions to reveal the menu. Click Create Resource. In the New Child Resource panel, for Resource Name type trips For Resource Path type trips Check the Enable API Gateway CORS checkbox Click Create Resource The /trips resource will be created. Click on the /trips link, then click the Actions button and choose Create Method. In the dropdown list that appears, choose GET Click the grey tick next to the dropdown list to commit the change. The /trips - GET - Setup panel will appear. For Lambda Region select ap-northeast-1 (or your region) In the Lambda Function field, type idevelop to reveal the available functions in the region and select idevelopTripSearchFull. Click Save. In the dialog that appears regarding adding permissions to Lambda, click OK. When the method is created, you will see the Method Execution panel: To test that the Lambda function is being called from the API, click the Test button.\nIn the Method Test panel, scroll down to reveal the Test button. Click the Test button. After a moment or two for the Lambda function to initialise and execute, you should see an output similar to this: Note that the data you see will be different because it is randomly generated by the lab setup process.\nTo allow access from a web browser, you need to enable CORS - Cross-origin scripting. Click on the /trips node and from the Actions menu, select Enable CORS. Click Enable CORS and replace existing CORS headers. On the dialog that appears, click Yes, replace existing values. When each of the listed items have a green tick against them, you can move on to the next section. This will only take a moment. Expose the /tripsfromcity RESTful API endpoint The first path we exposed was quite simple - /trips gets all the trips in the system. But we know our source code implementation allows us to specify a filter to query for trips that originate from a particular city or have a particular destination, so we want to expose this functionality to our API consumers. First, we will expose the /tripsfromcity path.\nClick the / root element in the Resources tree From the Actions menu choose Create Resource For Resource Name type tripsfromcity Check the Enable API Gateway CORS checkbox Click Create Resource Our call into the Lambda function requires a city parameter. We will follow the standard pattern for RESTful interfaces, and pass this parameter in as a URL parameter. With the /tripsfromcity node selected, from the Actions menu select Create Resource For Resource Name type {city} For Resource Path, delete the default and replace with {city} Click Create Resource With the /{city} node selected, from the Actions menu select Create Method In the dropdown list that appears, choose GET Click the grey tick next to the dropdown list to commit the change. The /tripsfromcity/{city} - GET - Setup panel will appear. For Lambda Region select ap-northeast-1 (or your target region) In the Lambda Function field, type idevelop to reveal the available functions in the region and select idevelopTripSearchFromCity Click Save In the dialog that appears regarding adding permissions to Lambda, click OK When the method is created, you will see the Method Execution panel, as before for the /trips resource. We can’t go ahead and test the API call just yet, because we need to transform the request through API Gateway so that the city parameter is passed through to the Lambda function correctly. The devlounge.lambda.FindTripsFromCityHandler handler expects to see the input data in this JSON format:\n{ \u0026#34;payload\u0026#34; : { \u0026#34;city\u0026#34;: \u0026#34;Melbourne\u0026#34; } } This would cause the Lambda function to search DynamoDB for all trips that originate from Melbourne. We need to add a Body Mapping Template for this method in API Gateway to correctly transform the request into this format.\nIn the /tripsfromcity/{city} - GET - Method Execution panel, click Integration Request Scroll down to Mapping Templates and open the section by clicking on the triangle to reveal the panel Select the When there are no templates defined (recommended) option Click Add mapping template For Content-Type type application/json and click the grey tick icon to commit the change Scroll further down to show the mapping template entry text field. Paste in the following template: { \u0026#34;payload\u0026#34; : { \u0026#34;city\u0026#34;: \u0026#34;$input.params(\u0026#39;city\u0026#39;)\u0026#34; } } Click Save. This template will take the parameter {city} from the URL and add it into a JSON payload that is sent to the Lambda function, as a property of the payload object, just as the Lambda function expects.\nThe schema defined here for this Lambda function is completely arbitrary, and in your own application you could use a completely different model. The mapping template gives you the flexibility to transform the inbound data on-the-fly through the API Gateway endpoint.\nWe can now test the API call. Click Method Execution to go back to the Method Execution panel. Click Test to reveal the test panel Under Path, for the {city} parameter, type Melbourne Click Test API Gateway will make the call into the Lambda function, passing the value Melbourne into the Body Mapping Template you have defined, which will insert the search parameter Melbourne into the JSON payload that is sent to the Lambda function. This will cause the function handler to consume the JSON and execute a search in the DynamoDB table, and return the results. You will see a result similar to this:\nTo allow access from a web browser, you need to enable CORS - Cross-origin scripting. Click on the /tripsfromcity/{city} node and from the Actions menu, select Enable CORS. Click Enable CORS and replace existing CORS headers On the dialog that appears, click Yes, replace existing values. When each of the listed items have a green tick against them, you can move on to the next section. This will only take a moment. Expose the /tripstocity RESTful API endpoint Next, we will expose the final resource for our Trips API, /tripstocity:\nClick the / root element in the Resources tree From the Actions menu choose Create Resource For Resource Name type tripstocity Check the Enable API Gateway CORS checkbox Click Create Resource Our call into the Lambda function requires a city parameter. We will follow the standard pattern for RESTful interfaces, and pass this parameter in as a URL parameter. With the /tripstocity node selected, from the Actions menu select Create Resource For Resource Name type {city} For Resource Path, delete the default and replace with {city} Check the Enable API Gateway CORS checkbox Click Create Resource With the /{city} node selected, from the Actions menu select Create Method In the dropdown list that appears, choose GET Click the grey tick next to the dropdown list to commit the change. The /tripstocity/{city} - GET - Setup panel will appear. For Lambda Region select ap-northeast-1 (or your target region) In the Lambda Function field, type idevelop to reveal the available functions in the region and select idevelopTripSearchToCity Click Save In the dialog that appears regarding adding permissions to Lambda, click OK When the method is created, you will see the Method Execution panel, as before for the /trips resource. We can’t go ahead and test the API call just yet, because we need to transform the request through API Gateway so that the city parameter is passed through to the Lambda function correctly. The devlounge.lambda.FindTripsToCityHandler handler expects to see the input data in this JSON format:\n{ \u0026#34;payload\u0026#34; : { \u0026#34;city\u0026#34;: \u0026#34;Melbourne\u0026#34; } } This would cause the Lambda function to search DynamoDB for all trips that have Melbourne as a destination. We need to add a Mapping Template for this method in API Gateway to correctly transform the request into this format.\nIn the /tripstocity/{city} - GET - Method Execution panel, click Integration Request Scroll down to Mapping Templates and open the section by clicking on the triangle to reveal the panel Select the When there are no templates defined (recommended) option Click Add mapping template For Content-Type type application/json and click the grey tick to commit the change Scroll further down to show the mapping template entry text field. Paste in the following template: { \u0026#34;payload\u0026#34; : { \u0026#34;city\u0026#34;: \u0026#34;$input.params(\u0026#39;city\u0026#39;)\u0026#34; } } Click Save This template will take the parameter {city} from the URL and add it into a JSON payload that is sent to the Lambda function, as a property of the payload object, just as the Lambda function expects.\nTest the /tripstocity API call to confirm it is functioning as expected. To allow access from a web browser, you need to enable CORS - Cross-origin scripting. Click on the /tripstocity/{city} node and from the Actions menu, select Enable CORS. Click Enable CORS and replace existing CORS headers On the dialog that appears, click Yes, replace existing values. When each of the listed items have a green tick against them, you can move on to the next section. This will only take a moment. If you have completed the steps above as described, you will have a resources tree that looks like this:\nDeploy the API and test Now that you have confirmed that the microservices are functioning correctly, you are ready to deploy the API and test it from the publicly available endpoint. Click the / root element of the API and click the Actions button. Select Deploy API In the Deploy API dialog that appears, for Deployment stage choose [New Stage] to create a new deployment stage. For Stage name type prod For Stage description type Trips API For Deployment description type Initial deployment Click Deploy The new stage prod will be created and you will see the prod Stage Editor\nClick the Invoke URL link. A new window will open and hit the stage endpoint. You will see an error message stating {\u0026quot;message\u0026quot;:\u0026quot;Missing Authentication Token\u0026quot;}. This is because there is no handler for the root of the stage - you have only defined resources/methods beneath the /trips, /tripsfromcity and /tripstocity paths. Edit the URL in the URL bar of the browser and append /trips then press Enter. The page will refresh, and then display all of the available trips as JSON. The output will be similar to this: { \u0026#34;succeeded\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;errorCode\u0026#34;: 0, \u0026#34;data\u0026#34;: [{ \u0026#34;date\u0026#34;: 1511866019000, \u0026#34;originCity\u0026#34;: \u0026#34;Dallas\u0026#34;, \u0026#34;destinationCity\u0026#34;: \u0026#34;Santigo de Chile\u0026#34;, \u0026#34;airline\u0026#34;: \u0026#34;Qantas\u0026#34; }, { \u0026#34;date\u0026#34;: 1514831014000, \u0026#34;originCity\u0026#34;: \u0026#34;London\u0026#34;, \u0026#34;destinationCity\u0026#34;: \u0026#34;Melbourne\u0026#34;, \u0026#34;airline\u0026#34;: \u0026#34;Qantas\u0026#34; }] } Test the other two methods /tripsfromcity and /tripstocity in a similar way, but this time, you need to provide the city to search for. For example, use /tripsfromcity/Melbourne to search for all trips that leave from Melbourne. If the data looks right, and there are no errors, you are ready to move on to the next exercise.\nExercise 2 - Use CloudFormation/SAM via the AWS CLI to deploy the HotelSearch microservice In the previous steps, you manually deployed and configured the TripSearch microservice, including the Lambda functions and API Gateway resources. You will have noticed that there are quite a few steps required, and doing this manually is time consuming and prone to errors. In this step, you will use the AWS CLI and CloudFormation/SAM to deploy the HotelSearch microservice, instead of manually deploying the resources.\nBy using CloudFormation/SAM, many of the manual steps will be taken care of for you, streamlining the deployment process. You will still have to manually trigger the process, but the actual deployment will be automated.\nThe HotelSpecials microservice needs to access a MySQL database to retrieve the hotel specials data. The lab environment has automatically deployed and seeded a database for you, and the connection details are provided in Cloudformation Outputs tab with instructions below on where to update the placeholder in the template you will use to deploy the microservice. The MySQL instance has been deployed using Amazon RDS and is not publicly-accessible since it is launched in a private subnet. Therefore, for the Lambda function to be able to connect to the database, the Lambda function will also need to be deployed into a private subnet by enabling VPC Integration. The template.yml file provided has all the required setup to do this, you just need to update the placeholders as per the below instructions.\nThe lab setup has created an S3 bucket for you to store the deployment artefact for the Lambda function for the HotelSpecials microservice. First, you need to test and build the deployment package. Download the source code bundle from HotelSpecials.zip and explode the zip file onto your filesystem.\nHotelSpecials source code bundle\rHotelSpecials.zip\r(35 ko)\rIn a terminal window, cd into the filesystem location where you exploded the HotelSpecials source code, and build the deployment artefact by issuing the following command: mvn package shade:shade The deployment artefact (JAR file) will be built and stored in ./target/hotelspecials-1.0.0.jar\nLocate the file template.yml in the HotelSpecials source code folder, and open it in a text editor such as Eclipse. Search/Replace the following placeholders with the actual values from Cloudformation Outputs tab: \u0026lt;DatabaseSecurityGroup\u0026gt; \u0026lt;DatabaseSubnet1\u0026gt; \u0026lt;DatabaseSubnet2\u0026gt; \u0026lt;RDSEndpoint\u0026gt; Save the template.yml file once you have made the changes.\nUse the AWS CLI to package the Lambda function (from the deployment artefact you just built). Run the following command from the commandline: aws cloudformation package --template template.yml --s3-bucket \u0026lt;S3BucketLambdaCode\u0026gt; --output-template template-export.yml Replace the with the value shown in Cloudformation Outputs tab for the key S3BucketLambdaCodeBucketName. Do not include the *\u0026lt;** and *\u0026gt;** symbols.\nThe command will upload the build artefact to the S3 bucket, and then update the template.yml pointer to the code artefact on S3, and write out a new template with this update included, to a file called template-export.yml\nIt will take a moment or two for the upload of the artefact to complete.\nUse the AWS CLI to create and deploy a CloudFormation Change Set: aws cloudformation deploy --template-file template-export.yml --stack-name HotelSpecialsAPI --capabilities CAPABILITY_IAM In the web browser, open the CloudFormation console. You should see an output like this: This indicates that the CloudFormation Change Set has been created. The command you issued will create the Change Set and then automatically execute the Change Set, so if you refresh the stack list again, you will see:\nThis indicates that the Change Set is being applied to the CloudFormation stack named HotelSpecialsAPI\nIt will take a few moments to complete the execution. If you refresh, you will eventually see:\nClick the HotelSpecialsAPI stack’s check box to highlight it, click the Events tab and review the steps that the CloudFormation template has applied to your environment. These will match the resources and actions in the template-output.yml file.\nWhen the Change Set has been executed, your HotelSpecials API has been deployed. Open the API Gateway console in the browser and under APIs, click the iDevelop - Hotel Specials API link to reveal the resources for the API:\nNote that a single GET method is defined, as per the template.yml CloudFormation template you deployed.\nClick on the GET method beneath /hotelspecials to reveal the /hotelspecials - GET - Method Execution panel. Click Integration Request The Integration Request panel will be shown. Note the Lambda Function specified: The specified value is not a Lambda function, but instead, is a Stage Variable that will be replaced at runtime by API Gateway. Therefore, in order for this API call to succeed, the Stage in API Gateway must have defined a value for the envHotelSpecials stage variable.\nClick on the Stages link beneath the iDevelop - Hotel Specials API on the left:\nClick on the prod stage link In the prod Stage Editor click the Stage Variables tab Note that a single variable is defined - envHotelSpecials - which correlates to the stage variable name the GET method was expecting. The value of the variable is GetHotelSpecials which is the name of the Lambda function that the template created using the JAR file you built and uploaded during the package/deploy process.\nUsing stage variables gives you a level of indirection at runtime, and also when designing your CloudFormation/SAM templates. You can update the value of a stage variable at any time without having to re-deploy the API.\nTest the HotelSpecials API You are now ready to test the HotelSpecials API.\nExpand the prod root element in the Stages list to reveal the hierarchy. Click on the GET method Click on the Invoke URL value in the prod - GET - /hotelspecials panel. After a moment while the Lambda function is initialised, you should see the JSON result of querying the mySQL database from the Lambda function. { \u0026#34;succeeded\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;errorCode\u0026#34;: 0, \u0026#34;data\u0026#34;: [{ \u0026#34;hotel\u0026#34;: \u0026#34;Sommerset Hotel\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Minimum stay 3 nights\u0026#34;, \u0026#34;cost\u0026#34;: 474, \u0026#34;expiryDate\u0026#34;: 1504064184038, \u0026#34;location\u0026#34;: \u0026#34;Sydney\u0026#34;, \u0026#34;id\u0026#34;: 1 }, { \u0026#34;hotel\u0026#34;: \u0026#34;Freedmom Apartments\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Pets allowed!\u0026#34;, \u0026#34;cost\u0026#34;: 501, \u0026#34;expiryDate\u0026#34;: 1504068564781, \u0026#34;location\u0026#34;: \u0026#34;Sydney\u0026#34;, \u0026#34;id\u0026#34;: 2 }] } If you see a JSON payload with no errors, you have successfully deployed an API and supporting Lambda function that queries the mySQL database.\nNotice how much quicker and easier that was to deploy without any manual intervention?\nThat is the power of automation. In the next exercise, we will take this one step further, using the (now familiar) CI/CD pipeline approach to deploy our next API.\n"
},
{
	"uri": "/3-aaa/3-deploy-test/",
	"title": "Deploy and Test",
	"tags": [],
	"description": "",
	"content": "Deploy and Test the new Behaviour\nYou must re-deploy the API in order for the changes to take effect on your API. From the Actions drop-down button, click Deploy API. Deploy the API to the prod stage. Switch over to your TravelBuddy SPA web page, and refresh it. Without entering a destination value, click the Go! button. After a moment, you should see a toaster element appear stating that you must be logged-in in order to use the feature. "
},
{
	"uri": "/2-prepare/2.3-connectvirtualmachine/",
	"title": "Connect to the Windows Instance",
	"tags": [],
	"description": "",
	"content": "Connect to the Windows Instance Go to Amazon EC2 console. On the left navigation bar, click Intances. Select DevAxWindowsHost. Click Connect. In the Connect to instance page Click tab RDP client. Click Download remote desktop file. We will download file remote desktop to the folder contains the key pair. Click Get password. In the Get Windows password page: Click Browse. Select file KPforDevAxInstances.pem we downloaded in the section 1.1. Click Decrypt Password to decrypt the password. Copy decrypted password . Open file DevAxWindowsHost.rdp we downloaded in step 2. Click Connect. Type the password we copied in step 4 Click OK. Click Don’t ask me again for connections to this computer. Click Yes. Connect successfully. Cấu hình AWS CLI Assign the Administrator Access to user awsstudent was created by Cloud Formation template Go to AWS IAM Console. Click Users. Click user awsstudent In the Permissions policies section Click Add permissions In the Add permissions to awsstudent page Click Attach existing policies directly Type AdministratorAccess to the search bar. Select AdministratorAccess Click Next:Review Click Add Permission Click tab Security credentials Click Create access key to create the access key Save Access key and Secret access key to use in the next steps Execute the below command: aws configure set profile.devaxacademy.region \u0026lt;your_region\u0026gt;\raws configure set profile.devaxacademy.aws_access_key_id \u0026lt;access_key_id\u0026gt;\raws configure set profile.devaxacademy.aws_secret_access_key \u0026lt;secret_access_key\u0026gt;\rgit config --global user.email \u0026lt;YOUR_EMAIL\u0026gt;\rgit config --global user.name awsstudent Change \u0026lt;your_region\u0026gt; by Region code Change \u0026lt;access_key_id\u0026gt; by Access Key Id we saved in step 6\nChange \u0026lt;secret_access_key\u0026gt; by Secret Access Key we saved in step 6\n"
},
{
	"uri": "/3-create-single-page-app/3.3-create-api-with-api-gateway/",
	"title": "Create And Expose the API with Amazon API Gateway",
	"tags": [],
	"description": "",
	"content": "Create And Expose the API with Amazon API Gateway Go to AWS API Gateway console. In the Choose an API type section, find REST API - Develop a REST API where you gain complete control over the request and response along with API management capabilities. Click Build Click OK In the Create new API section, select New API In the API name section, type iDevelop - Trip Search API In the Description section, type Allows searching ở trips from/to cities Click Create API The API will be created, and have a root path element and nothing else. Click Actions Click Create Resource In the New Child Resource page In the Resource Name section, type trips Check Enable API Gateway CORS Click Create Resource The /trips resource will be created. Click on the /trips link Click Actions Click Create Method In the dropdown list that appears, select GET Click the grey tick next to the dropdown list to commit the change. In the Lambda Region section, select your Region In the Lambda Function section, type idevelop and select idevelopTripSearchFull Click Save Click OK When the method is created, you will see the Method Execution panel: Click Test Click Test After a moment or two for the Lambda function to initialise and execute, you should see an output similar to this: Click /trips Click Actions Click Enable CORS Click Enable CORS and replace existing CORS headers Click Yes, replace existing values When each of the listed items have a green tick against them, you can move on to the next section. This will only take a moment. Expose the /tripsfromcity RESTful API endpoint The first path we exposed was quite simple - /trips gets all the trips in the system. But we know our source code implementation allows us to specify a filter to query for trips that originate from a particular city or have a particular destination, so we want to expose this functionality to our API consumers. First, we will expose the /tripsfromcity path.\nIn the Resources section, click / Click Actions Click Create Resource In the Resource Name section, type tripsfromcity Select Enable API Gateway CORS Click Create Resource Our call into the Lambda function requires a city parameter. We will follow the standard pattern for RESTful interfaces, and pass this parameter in as a URL parameter. Select /tripsfromcity Click Actions Click Create Resource In the Resource Name section, type {city} In the Resource Path section, delete the default and replace with {city} Click Create Resource Click /{city} Click Actions Click Create Method In the dropdown list that appears, select GET Click the grey tick next to the dropdown list to commit the change. In the Lambda Region section, select your Region In the Lambda Function section, type idevelop and select idevelopTripSearchFromCity Click Save Click OK When the method is created, you will see the Method Execution panel. as before for the /trips resource. We can’t go ahead and test the API call just yet, because we need to transform the request through API Gateway so that the city parameter is passed through to the Lambda function correctly. The devlounge.lambda.FindTripsFromCityHandler handler expects to see the input data in this JSON format:\n{\r\u0026#34;payload\u0026#34; : {\r\u0026#34;city\u0026#34;: \u0026#34;Melbourne\u0026#34;\r}\r} This would cause the Lambda function to search DynamoDB for all trips that originate from Melbourne. We need to add a Body Mapping Template for this method in API Gateway to correctly transform the request into this format.\nClick Integration Request Click Mapping Templates Click When there are no templates defined (recommended) Click Add mapping template In the Content-Type section , type application/json Click the grey tick icon to commit the change. Scroll further down to show the mapping template entry text field. Paste in the following template: {\r\u0026#34;payload\u0026#34; : {\r\u0026#34;city\u0026#34;: \u0026#34;$input.params(\u0026#39;city\u0026#39;)\u0026#34;\r}\r} This template will take the parameter {city} from the URL and add it into a JSON payload that is sent to the Lambda function, as a property of the payload object, just as the Lambda function expects.\nClick Save The schema defined here for this Lambda function is completely arbitrary, and in your own application you could use a completely different model. The mapping template gives you the flexibility to transform the inbound data on-the-fly through the API Gateway endpoint.\nClick Method Execution Click Test In the Path section, in {city} field, type Melbourne Click Test API Gateway will make the call into the Lambda function, passing the value Melbourne into the Body Mapping Template you have defined, which will insert the search parameter Melbourne into the JSON payload that is sent to the Lambda function. This will cause the function handler to consume the JSON and execute a search in the DynamoDB table, and return the results. You will see a result similar to this: Select /{city} in /tripsfromcity section Click Actions Click Enable CORS Click Enable CORS and replace existing CORS headers Click Yes, replace existing values When each of the listed items have a green tick against them, you can move on to the next section. This will only take a moment. Click / in Resources section Click Actions Click Create Resource In the Resource Name section, type tripstocity Select Enable API Gateway CORS Click Create Resource Our call into the Lambda function requires a city parameter. We will follow the standard pattern for RESTful interfaces, and pass this parameter in as a URL parameter. Click /tripstocity Click Actions Click Create Resource In the Resource Name section, type {city} In the Resource Path section, delete the default and replace with {city} Select Enable API Gateway CORS Click Create Resource Click /{city} in the section /tripstocity Click Actions Click Create Method In the dropdown list that appears, select GET Click the grey tick next to the dropdown list to commit the change. In the Lambda Region section, select your Region In the Lambda Function section, type idevelop and select idevelopTripSearchToCity Click Save Click OK When the method is created, you will see the Method Execution panel, as before for the /tripsfromcity resource. We again need to transform the request through API Gateway so that the city parameter is passed through to the Lambda function correctly, before we can test this API call. The devlounge.lambda.FindTripsToCityHandler handler expects to see the input data in this JSON format:\n{\r\u0026#34;payload\u0026#34; : {\r\u0026#34;city\u0026#34;: \u0026#34;Melbourne\u0026#34;\r}\r} This would cause the Lambda function to search DynamoDB for all trips that have Melbourne as a destination. We need to add a Mapping Template for this method in API Gateway to correctly transform the request into this format.\nClick Integration Request Click Mapping Templates Select When there are no templates defined (recommended) Click Add mapping template In the Content-Type section, type application/json Click the grey tick to commit the change Scroll further down to show the mapping template entry text field. Paste in the following template: {\r\u0026#34;payload\u0026#34; : {\r\u0026#34;city\u0026#34;: \u0026#34;$input.params(\u0026#39;city\u0026#39;)\u0026#34;\r}\r} Click Save Click Method Execution Click Test In the Path section, in the {city} field, type Melbourne Click Test API Gateway will make the call into the Lambda function, passing the value Melbourne into the Body Mapping Template you have defined, which will insert the search parameter Melbourne into the JSON payload that is sent to the Lambda function. This will cause the function handler to consume the JSON and execute a search in the DynamoDB table, and return the results. You will see a result similar to this: Click /{city} in /tripstocity section Click Actions Click Enable CORS Click Enable CORS and replace existing CORS headers Click Yes, replace existing values When each of the listed items have a green tick against them, you can move on to the next section. This will only take a moment. If you have completed the steps above as described, you will have a resources tree that looks like this: Deploy the API and test Now that you have confirmed that the microservices are functioning correctly, you are ready to deploy the API and test it from the publicly available endpoint. In the Resources section, click / Click Actions Click Deploy API In the Deployment stage section, select [New Stage] to create a new deployment stage. In the Stage name section, type prod In the Stage description section, type Trips API In the Deployment description section, type Initial deployment Click Deploy The new stage prod will be created and you will see the prod Stage Editor Click Invoke URL A new window will open and hit the stage endpoint. You will see an error message stating {\u0026ldquo;message\u0026rdquo;:\u0026ldquo;Missing Authentication Token\u0026rdquo;}. This is because there is no handler for the root of the stage - you have only defined resources/methods beneath the /trips, /tripsfromcity and /tripstocitypaths. Edit the URL in the URL bar of the browser and append /trips then press Enter. The page will refresh, and then display all of the available trips as JSON. The output will be similar to this: Test the /tripsfromcity method, use /tripsfromcity/Melbourne to search for all trips that leave from Melbourne. Test the /tripstocity method, use /tripstocity/Melbourne to search for all trips that go to Melbourne. NIf the data looks right, and there are no errors, you are ready to move on to the next exercise.\nUse CloudFormation/SAM via the AWS CLI to deploy the HotelSearch microservice In the previous steps, you manually deployed and configured the TripSearch microservice, including the Lambda functions and API Gateway resources. You will have noticed that there are quite a few steps required, and doing this manually is time consuming and prone to errors. In this step, you will use the AWS CLI and CloudFormation/SAM to deploy the HotelSearch microservice, instead of manually deploying the resources.\nBy using CloudFormation/SAM, many of the manual steps will be taken care of for you, streamlining the deployment process. You will still have to manually trigger the process, but the actual deployment will be automated.\nThe HotelSpecials microservice needs to access a MySQL database to retrieve the hotel specials data. The lab environment has automatically deployed and seeded a database for you, and the connection details are provided in Cloudformation Outputs tab with instructions below on where to update the placeholder in the template you will use to deploy the microservice. The MySQL instance has been deployed using Amazon RDS and is not publicly-accessible since it is launched in a private subnet. Therefore, for the Lambda function to be able to connect to the database, the Lambda function will also need to be deployed into a private subnet by enabling VPC Integration. The template.yml file provided has all the required setup to do this, you just need to update the placeholders as per the below instructions.\nHotelSpecials Project\rHotelSpecials.zip\r(33 ko)\rDownload the HotelSpecials.zip file and extract Open Command Prompt and navigate to the directory of the HotelSpecials project was extracted in step 65 Execute the following command: set AWS_PROFILE=devaxacademy\rmvn package shade:shade 67. When the target JAR is built, whick is in the target folder of the project and whose name is hotelspecials-1.0.0.jar 68. Go to AWS CloudFormation Console.\nClick Stack. Type DevAx-06 to the search bar and press Enter. Click DevAx-06. Click tab Output Save the value of DatabaseSecurityGroup, DatabaseSubnet1, DatabaseSubnet2, RDSEndpoint and S3BucketLambdaCodeBucketName to use in the next step. In the Eclipse IDE, open the template.yml file Replace \u0026lt;DatabaseSecurityGroup\u0026gt; by the DatabaseSecurityGroup value we saved in step 69 Replace \u0026lt;DatabaseSubnet1\u0026gt; by the DatabaseSubnet1 value we saved in step 69 Replace \u0026lt;DatabaseSubnet2\u0026gt; by the DatabaseSubnet2 value we saved in step 69 Replace \u0026lt;RDSEndpoint\u0026gt; by the RDSEndpoint value we saved in step 69 Save In the Command Prompt, execute the following command to package the Lambda function aws cloudformation package --template template.yml --s3-bucket \u0026lt;S3BucketLambdaCodeBucketName\u0026gt; --output-template template-export.yml Replace \u0026lt;S3BucketLambdaCodeBucketName\u0026gt; by the S3BucketLambdaCodeBucketName value we saved in step 69\nThe command will upload the build artefact to the S3 bucket, and then update the template.yml pointer to the code artefact on S3, and write out a new template with this update included, to a file called template-export.yml\nIt will take a moment or two for the upload of the artefact to complete.\n73. Execute the following command to create and deploy a CloudFormation Change Set\naws cloudformation deploy --template-file template-export.yml --stack-name HotelSpecialsAPI --capabilities CAPABILITY_IAM 74. Go to AWS CloudFormation Console.\nClick Stack. You will see the HotelSpecialsAPI stack. This indicates that the CloudFormation Change Set has been created. The command you issued will create the Change Set and then automatically execute the Change Set. It will take a few moments to complete the execution Select HotelSpecialsAPI stack, click tab Events and eview the steps that the CloudFormation template has applied to your environment. These will match the resources and actions in the template-output.yml file. Go to AWS API Gateway console Click iDevelop - Hotel Specials API Click Get Click Integration Request The Integration Request panel will be shown. Lambda Function specified: The specified value is not a Lambda function, but instead, is a Stage Variable that will be replaced at runtime by API Gateway. Therefore, in order for this API call to succeed, the Stage in API Gateway must have defined a value for the envHotelSpecials stage variable.\nClick Stages Click prod Click tab Stage Variables a single variable is defined - envHotelSpecials - which correlates to the stage variable name the GET method was expecting. The value of the variable is GetHotelSpecials which is the name of the Lambda function that the template created using the JAR file you built and uploaded during the package/deploy process.\nTest the HotelSpecials API Expand the prod root element in the Stages list to reveal the hierarchy. Click Get Click Invoke URL After a moment while the Lambda function is initialised, you should see the JSON result of querying the mySQL database from the Lambda function If you see a JSON payload with no errors, you have successfully deployed an API and supporting Lambda function that queries the mySQL database. Notice how much quicker and easier that was to deploy without any manual intervention? That is the power of automation. In the next exercise, we will take this one step further, using the (now familiar) CI/CD pipeline approach to deploy our next API.\n"
},
{
	"uri": "/3-create-single-page-app/",
	"title": "Creating A Single Page Application",
	"tags": [],
	"description": "",
	"content": "Overview In this exercise you will create the Single Page Application (SPA) website for TravelBuddy. A single-page application is a web application or website that interacts with the user by dynamically rewriting the current web page with new data from the web server, instead of the default method of the browser loading entire new pages. The SPA will interact with a set of APIs exposed by API Gateway.\nContent: Create A DynamoDB Table Manually Build And Deploy A Serverless Microservice Create And Expose the API with Amazon API Gateway Deploy the api using code star and CI/CD Setup The Single Page Application Website Build A Client To Consume The API "
},
{
	"uri": "/4-configure-aaa/4.3-deploy-and-test/",
	"title": "Deploy And Test",
	"tags": [],
	"description": "",
	"content": "Deploy And Test The New Behaviour Click Actions Click Deploy API In the Deployment stage section, select prod Click Deploy Switch over to your TravelBuddy SPA web page and refresh it. Without entering a destination value, click the Go! button. After a moment, you should see a toaster element appear stating that you must be logged-in in order to use the feature. "
},
{
	"uri": "/1-prerequisites/1-create-environment/3-rds/",
	"title": "RDS",
	"tags": [],
	"description": "",
	"content": "RDS Dịch vụ cơ sở dữ liệu quan hệ của Amazon (Amazon RDS) giúp dễ dàng thiết lập, vận hành và mở rộng quy mô cơ sở dữ liệu quan hệ trên đám mây. Nó cung cấp khả năng tiết kiệm chi phí và có thể thay đổi kích thước trong khi tự động hóa các tác vụ quản trị tốn thời gian như cung cấp phần cứng, thiết lập cơ sở dữ liệu, vá lỗi và sao lưu.\nTruy cập bảng điều khiển RDS Chọn Database Bạn sẽ thấy một database mới được tạo, chọn vào database này Database được tạo đã được cấu hình với các dịch vụ VPC, Security Groups,\u0026hellip; "
},
{
	"uri": "/4-xray/",
	"title": "Application Performance",
	"tags": [],
	"description": "",
	"content": "Tracing Application Performance With AWS X-Ray\nThe TripSearch, HotelSpecials and FlightSpecials Lambda functions each contain the necessary dependencies to support emitting tracing events to AWS X-ray, to allow you to easily trace the calls between the components of your distributed system. In this exercise, you will enable the feature and review the AWS X-ray console.\nIn the AWS Lambda Console, click on the Lambda function idevelopTripSearchFull. Select the Configuration tab then select the Monitoring and operations tools panel. Click the Edit button then enable the Active tracing in the AWS X-Ray section. Click Save. Switch over to the TravelBuddy SPA webpage that you have hosted in the S3 bucket. Sign in to the application if you are not already signed in. Click the Go! button without any text entered, to invoke the idevelopTripSearchFull Lambda function. It will take a moment to complete because you have changed the configuration for the Lambda function so it will be a cold start. After the dialog is shown displaying the trips, switch back to the AWS console, select Services and type X-ray. Click the X-ray item in the list to open the AWS X-ray console. In the AWS X-Ray page, click Get started then click Cancel. Select the Service map on the navigation panel. You will see a Service map that looks similar to this: You can now also see the service map directly from Lambda console.\nClick the first green circle which indicates the call into the Lambda function. The Details panel will appear. This panel shows information such as the response distribution histogram where you can easily see what percentage of calls are taking various amounts of time to execute. Click View Traces, this is at the bottom of the Service details which just showed up. In the Traces list click the link for the first item The Traces details panel will appear. You will be able to see a timeline view of the various actions and their execution durations, such as: Here, you can see that the overall call took 5 sec, 1.3 sec of which was taken by the scan of the TravelBuddyTripSectors DynamoDB table.\nEnable active tracing on the other Lambda functions that have been created as part of this lab: idevelopTripSearchFull, idevelopTripSearchFromCity, idevelopTripSearchToCity and GetHotelSpecials. You can do this manually using the console. However, note that the function created through automation with a name starting with awscodestar will have its configuration overwritten if you re-deploy the code. See the next Challenge Exercise to address this.\n"
},
{
	"uri": "/2-spa/4-codestar-cicd/",
	"title": "Deploy the API using CodeStar and CI/CD",
	"tags": [],
	"description": "",
	"content": "The next microservice we need for our TravelBuddy serverless application is the FlightSpecials API. We have seen FlightSpecials before in this course, so it should be familiar to you. It functions the same way as the HotelSpecials API in that it must be deployed with VPC integration so it can connect to the mySQL database to query for data. Instead of manually packaging and deploying this microservice, we will use CodeStar to build out a full CI/CD pipeline for us, as we have done in previous labs. So, since you have created CI/CD pipelines using AWS CodeStar a few times now, we are not going to provide you with full step-by-step instructions. If you need help, ask a Lab Assistant how to complete the tasks required to create a new CodeStar project and deploy the FlightSpecials code over the sample application provided by CodeStar.\nDepending on whether you chose to use the Eclipse environment or AWS Cloud9 choose the appropriate lab instructions below:\nContents\nOption A: Eclipse Environment Option B: AWS Cloud9 Environment "
},
{
	"uri": "/3-aaa/4-signup-signin/",
	"title": "User Sign Up/Sign In",
	"tags": [],
	"description": "",
	"content": "Add new User Sign Up and Sign In\nWe almost have everything we need to sign up and login as a user. Lets check whether the Cognito federated identities have been set up correctly.\nOpen Amazon Cognito in the console and click on Manage Identity Pools Open the TravelBuddy identity pool by clicking on its title. Click on Edit identity pool in the top right hand corner Here we can set up Unauthenticated roles (roles which are assumed when a user is not signed in), and Authenticated roles (roles which are assumed when a user is signed in).\nVerify that the Unauthenticated role is set to the role that contains the string CognitoIAMUnauthenticatedRole. This was created during lab setup. Verify that Authenticated role is set to the role that contains the string CognitoIAMAuthenticatedRole. This was also created during lab setup. You now have everything in place to register and sign-in as a user, and then test the signed-in behaviour of the /trips microservice now that it is protected by requiring authorization.\nIn the TravelBuddy web page, click Login or Register in the top navigation bar Click Sign-up here! Fill out the details to create your account. Note that you must provide a valid email address and one that you have access to immediately, in order to retrieve the verification code you will be sent.\nCheck your email, retrieve the verification code, and enter it into the Registration Verification Code dialog that appears. Click Verify. Sign-in using the credentials (email address and password) you provided during registration. You will now be signed in, and the banner will change to show My Account. Click the link - the only feature that is implemented is the Logout option. You can log out and then log back in again as you wish.\nNow that you are signed in, click the Go! button again without any text entered. Note that you are shown the full trips list in a dialog, as before we secured the call.\nNow, sign out using the My Account menu link, and try the Go! button again.\nNote that you see the error message again, indicating that you must be signed-in to use the /trips microservice.\n"
},
{
	"uri": "/4-configure-aaa/4.4-add-new-user-signup_signin/",
	"title": "Add New User Sign Up and Sign In",
	"tags": [],
	"description": "",
	"content": "Add New User Sign Up and Sign In Go to Amazon Cognito Console. Click Federated Identities Click TravelBuddy Click Edit identity pool Here we can set up Unauthenticated roles (roles which are assumed when a user is not signed in), and Authenticated roles (roles which are assumed when a user is signed in). Verify that the Unauthenticated role is set to the role that contains the string CognitoIAMUnauthenticatedRole. This was created during lab setup. Verify that the Authenticated role is set to the role that contains the string CognitoIAMAuthenticatedRole. This was created during lab setup. You now have everything in place to register and sign-in as a user, and then test the signed-in behaviour of the /trips microservice now that it is protected by requiring authorization.\nIn the TravelBuddy page, click Login or Register Click Sign-up here! In the First Name section, type your first name In the Last Name section, type your last name In the Email Address section, type your email You must provide a valid email address and one that you have access to immediately, in order to retrieve the verification code you will be sent.\nIn the Password section, type your password Click Register Check your email, save the verification code In the Verification Code section, type the verification code we saved in step 8 Click Verify Sign-in using the credentials (email address and password) you provided during registration. You will now be signed in and the banner will change to show My Account Click My Account, we will see the only feature that is implemented is the Logout option. Click Go! without any text entered. We are shown the full trips list in a dialog Sign out and click Go! without any text entered. We will see the error message again. "
},
{
	"uri": "/4-configure-aaa/",
	"title": "Configure Authentication, Authorization and Accounting (AAA)",
	"tags": [],
	"description": "",
	"content": "Overview Right now, our TravelBuddy SPA does not require any authentication in order to call the API services we have exposed. The lab setup process has provisioned a Cognito User Pool and a Cognito Identity Pool in your account. The Cognito User Pool is your fully-managed system of record for users in your application. The Identity Pool is used to obtain temporary AWS IAM credentials to sign requests that require SigV4 signing. The Cognito Identity Pool federates between multiple Identity Providers, but in our lab example, we only have one Identity Provider (the User Pool). Our TravelBuddy SPA does not actually have the requirement for IAM credentials, but we have implemented the feature to demonstrate how you can accomplish this. As a Challenge Exercise, we will ask you to implement AWS IAM Authorisation for a call into API Gateway, but this is an optional task for the lab.\nContent: Add Authentication to the SPA using Amazon Cognito User Pools Setting Up Authentication For The Microservice Deploy And Test Add New User Sign Up and Sign In "
},
{
	"uri": "/3-create-single-page-app/3.4-deploy-api-with-codestar/",
	"title": "Deploy the api using code star and CI/CD",
	"tags": [],
	"description": "",
	"content": "Create a CI/CD pipeline with AWS CodeStar Go to AWS CodeStar Console. Click Projects Click Create project Click Create service role if you never go to AWS CodeStar Service before.\nIn the Templates page, select Java and AWS Lambda Select Java Spring Click Next In the Project name section, type FlightSpecialsAPI Click Next In the Review page, click Create project Add awsstudent account to the the team with Owner role. Click Team Click Add team member In the Team member details section In the User section, select awsstudent In the Email address section, type your email In the Project role section, select Owner CLick Allow SSH access to project instances. Click Add team member Check added team member Go to AWS CloudFormation Console. Click Stack. Type DevAx-06 to the search bar and click Enter. Click DevAx-06. Click tab Output Save GitPassword value and GitUserName value to use in the next step. Open Eclipse IDE. Find the AWS Icon and click it to reveal the menu Click Import AWS CodeStar Project… Select your region Select FlightSpecialsAPI Type the saved information in step 9 to User name section and Password section Click Next Click OK, ignore the error org.eclipse.egit.ui.internal.repository.tree.RepositoryTreeNodeType.getIcon()Lorg/eclipse/swt/graphics/Image; Select master branch and click Next. Click Finish. Click No to skip setup password hint. Project sample was created by CodeStar was imported Open Command Prompt, execute the below command to go to the directory where the IDE code is located and to create and switch to the new branch cd C:\\Users\\Administrator\\git\\FlightSpecialsAPI\rgit checkout -b \u0026#34;new-implementation\u0026#34; FlightSpecials Project\rFlightSpecials.zip\r(15 ko)\rDownload the FlightSpecials.zip file and extract. In the Command Prompt, navigate to the directory of the FlightSpecials folder we extracted in step 17 Execute the following command to overwrite the implementation provided by CodeStar with the contents of the FlightSpecials.zip file we extracted in step 17. We have provided a copy_files.sh script in the FlightSpecials.zip bundle that you can use copy_files.sh C:\\Users\\Administrator\\git\\FlightSpecialsAPI 19. In the Eclipse IDE, right-click on the FlightSpecialsAPI project we imported\nClick Maven Click Update Project\u0026hellip; In the Eclipse IDE, open the pom.xml file After the line 113, add the following content \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.0.3.RELEASE\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-autoconfigure\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.0.3.RELEASE\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.json\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;json\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;20180130\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.amazonaws.serverless\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;aws-serverless-java-container-core\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.1.3\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.junit.jupiter\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;junit-jupiter-api\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;5.2.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt; Save Give CloudFormation permission to create an IAM role Go to AWS IAM Console. Click Roles. Type CodeStarWorker-flightspecialsa-CloudFormation to the search bar and press Enter Click CodeStarWorker-flightspecialsa-CloudFormation. If you can’t find the role, it may be too early - CodeStar may still be provisioning the pipeline and may not yet have created the role. Check the progress of the provisioning in the CodeStar dashboard.\nClick Add permissions Click Attach Policies Type idevelop to the search bar and press Enter Select idevelopCodeStarCloudFormationPolicy Click Attach Policies Update placeholder parameters in the CloudFormation template Trong Eclipse IDE, open the template.yml file Do the same step 68 and step 69 in the 3.3 section to get the DatabaseSecurityGroup value, the DatabaseSubnet1 value, the DatabaseSubnet2 value and the RDSEndpoint value Replace \u0026lt;DatabaseSecurityGroup\u0026gt; with the DatabaseSecurityGroup value Replace \u0026lt;DatabaseSubnet1\u0026gt; with the DatabaseSubnet1 value Replace \u0026lt;DatabaseSubnet2\u0026gt; with the DatabaseSubnet2 value Replace \u0026lt;RDSEndpoint\u0026gt; with the RDSEndpoint value Save Update the target AWS region in the swagger.yml API definition file The swagger.yml file provided in the zip bundle is the definition for the API that exposes the microservice via Amazon API Gateway. It needs to be updated with details of your lab AWS Account Id and target AWS Region before you can deploy your microservice.\nIn the Eclipse IDE, open the swagger.yml file Press Ctrl+F shortcut In the Find section, type REPLACE_AWS_REGION In the Replace with section, type your Region Click Replace All to replace In the Find section, type REPLACE_AWS_ACCOUNTID In the Replace with section, type your AWS Account Id Click Replace All to replace Save Now that you have completed updating files, you need to add the changed files to your new-implementation git branch and commit the files. Open Command Prompt, execute the below command to navigate to the directory of the FlightSpecialsAPI folder and review the changed code files cd C:\\Users\\Administrator\\git\\FlightSpecialsAPI\rgit status 28. Execute the below command to add in the changed files\ngit add .\rgit commit -m \u0026#34;Baseline implementation\u0026#34; 29. Execute the below command to switch back to the master branch\ngit checkout master 30. Execute the below command to merge the changes for your new-implementation branch into the master branch\ngit merge new-implementation 31. In the Eclipse IDE, right-click on the FlightSpecialsAPI project\nClick Team Click Push to origin. Click Close You need to perform the push from Eclipse because the git credentials are embedded within the Eclipse environment. You could also configure the command line environment with the git credentials but that is beyond the scope of this lab.\nIt will take a few moments to push the code and commence the deployment. Checking in the source code and templates will trigger the pipeline to build and deploy the new implementation. AWS CodePipeline will now use CloudFormation to deploy the following resources:\nThe Lambda function implemented by the Java code you checked into CodeCommit IAM role for the Lambda function API Gateway configuration for the API While you have some time, spend a few minutes to explore the buildspec.yml, swagger.yml and template.yml files which define the Amazon API Gateway, AWS Lambda function and the build/deployment process through AWS CodeBuild. You will notice that the builspec.yml file uses the same AWS CLI command to package the deployment that you used when you manually packaged the HotelSpecials API earlier.\nDo not execute these commands below, they are here as a reference!\nmvn package shade:shade\raws cloudformation package --template template.yml --s3-bucket $S3_BUCKET --output-template template-export.yml The template.yml file uses the Serverless Application Model (SAM) transform to define the REST API, as opposed to how we approached this in the HotelSpecials API example. In HotelSpecials, the CloudFormation template used canonical CloudFormation to define the REST API so that it could be explicit about the API definition and include the swagger definition inline. The FlightSpecials example uses a more declarative approach and left the details to SAM. You are free to mix CloudFormation and SAM in the same template, as you can see from these examples.\nTest the FlightSpecials API Go to AWS API Gateway console Type iDevelop - Flight Specials API to the search bar and press Enter Click iDevelop - Flight Specials API Click Stages Expand the prod root element Click GET Click Invoke URL After a moment while the Lambda function is initialised, you should see the JSON result of querying the mySQL database from the Lambda function If you see a JSON payload with no errors, you have successfully deployed an API and supporting Lambda function that queries the mySQL database. Notice how much quicker and easier that was to deploy without any manual intervention, and you didn’t even have to interact with the AWS CLI or Console? Everything was driven by the source control check-in process.\nYou are now ready to integrate these APIs with the TravelBuddy web site.\n"
},
{
	"uri": "/5-challenge/",
	"title": "Challenge",
	"tags": [],
	"description": "",
	"content": "As an optional task, you are challenged with implementing active tracing using automation for the functions deployed using the AWS CLI and CodeStar. We are not going to give you all the answers! But to help you on your journey, check out the AWS::Lambda::Function CloudFormation documentation, and AWS SAM documentation.\nWhen you have fully implemented tracing for the Lambda functions, you will see the tracing segments on the AWS X-ray console. Trigger the execution of the various lambda functions using the TravelBuddy SPA web page, and you will see results such as:\n"
},
{
	"uri": "/2-spa/5-setup-spa/",
	"title": "Setup the SPA Webpage",
	"tags": [],
	"description": "",
	"content": "Setup the Single Page Application Website\nNow that we have our three APIs set up, we are ready to call them from a web page. First, we need to set up our single-page web application (SPA) and host it on Amazon S3.\nWe have decided to use the AngularJS framework for our SPA. You could of course use any suitable framework. The aim of this Lab is not to teach you AngularJS or any other SPA framework, so we won’t be diving into the details of how the page works, other than to guide you through wiring up the API calls that the SPA will need to make to populate its data elements.\nContents\nGenerate client SDKs for each of the three APIs and deploy to the SPA Push SPA files to Amazon S3 Download the source code bundle from www.zip and explode the zip file onto your filesystem. Source code bundle\rwww.zip\r(5660 ko)\rGenerate client SDKs for each of the three APIs and deploy to the SPA The SPA implementation you have been provided has stubbed-out implementations of the three APIs we want to expose to our users. They have just enough implementation to not cause an error on the page when executed, but they do not provide any data. In order to ‘wire up’ our APIs to the SPA, we will need to generate the Javascript client SDKs that relate to these APIs and store them in the appropriate path.\nFor each of the three APIs we have created, follow these instructions, using either the name TripSearch, HotelSpecials or FlightSpecials as appropriate:\nOpen the API Gateway console in the browser and under APIs, click the iDevelop - Flight Specials API link to reveal the resources for the API. Click Stages Click prod Click SDK Generation For Platform, choose Javascript Click Generate SDK. The Javascript SDK for the API will be downloaded by your browser. Explode the downloaded ZIP file on your filesystem, and locate the file apigClient.js Rename this file as apigClient_FlightSpecials.js Open the renamed file in the Eclipse/Cloud9 IDE. Edit it as a text file - simply drag it into the IDE or open the file using the menu. Using the Search/Replace feature, replace all occurrences of the text apigClientFactory with apigClientFactory_FlightSpecials. There will be 2 occurrences to replace, both at the start of the file. Save the file Copy the file from its current location on your filesystem, to the api folder inside the www folder inside the working folder for the SPA on your local development environment. Replace the file that was provided in the ZIP file you downloaded. REPEAT the above set of instructions for this exercise two times - one for each of TripSearch and HotelSpecials APIs, ensuring that you name the apigClient.js files in each downloaded SDK apigClient_HotelSpecials.js and apigClient_TripSearch.js as appropriate, and that you search/replace apigClientFactory in each, with apigClientFactory_HotelSpecials and apigClientFactory_TripSearch as appropriate.\nPush SPA files to Amazon S3 With the API SDKs in place, you are now ready to deploy the SPA code to the Amazon S3 Bucket that will serve the website. The lab setup process has provisioned a suitable S3 bucket, with WebSite Hosting enabled. So you will only need to push all the files from your local machine to the S3 bucket to be able to test the application.\nIn a commandline terminal, cd into the directory where your working copy of the SPA website is located Issue the following command to synchronize between your local machine and the S3 bucket. Be sure to replace the with the value specified in Cloudformation Outputs tab: aws s3 sync . s3://\u0026lt;S3BucketWWW\u0026gt; --acl public-read When the synchronize has completed, you are ready to test your SPA hosted on S3. Open the following URL in the web browser, replacing the name of the S3 bucket with the value shown in the lab cloudformation S3BucketWWW field: http://\u0026lt;S3BucketWWW\u0026gt;.s3-website-ap-southeast-2.amazonaws.com The familiar TravelBuddy website should render in your browser. Previously you have seen this website when it was served from a monolithic Java application served off EC2 managed by Elastic Beanstalk. But now, the site is a single-page web application, and is hosted from an S3 bucket, making API calls to Amazon API Gateway to provide data to the website.\nYou should see the Hotel Specials and Flight Specials listings rendered on the page.\nIn addition, a Find trips to\u0026hellip; option is available. To test this, enter Melbourne in the text field and click the Go! button. A dialog will appear showing the results of the search. This data is being served from a call to the TripSearchAPI call, for /tripsfromcity.\nIf you clear the value in the field and click the Go! button, you will see a list of all available trips, which is served from the TripSearchAPI call for /trips.\nIf you are not seeing the data as a result of the API calls, take a look at the developer console in the browser, to see if there are any errors that will help track down the issue.\n"
},
{
	"uri": "/3-create-single-page-app/3.5-setup-single-page-app-website/",
	"title": "Setup The Single Page Application Website",
	"tags": [],
	"description": "",
	"content": "Setup The Single Page Application Website Now that we have our three APIs set up, we are ready to call them from a web page. First, we need to set up our single-page web application (SPA) and host it on Amazon S3.\nWe have decided to use the AngularJS framework for our SPA. You could of course use any suitable framework. The aim of this Lab is not to teach you AngularJS or any other SPA framework, so we won’t be diving into the details of how the page works, other than to guide you through wiring up the API calls that the SPA will need to make to populate its data elements.\nSPA Project\rwww.zip\r(5660 ko)\rDownload the www.zip file and extract Generate client SDKs for each of the three APIs and deploy to the SPA The SPA implementation you have been provided has stubbed-out implementations of the three APIs we want to expose to our users. They have just enough implementation to not cause an error on the page when executed, but they do not provide any data. In order to ‘wire up’ our APIs to the SPA, we will need to generate the Javascript client SDKs that relate to these APIs and store them in the appropriate path.\nGo to AWS API Gateway console Type iDevelop - Flight Specials API to the search bar and press Enter Click iDevelop - Flight Specials API Click Stages Select prod Click tab SDK Generation In the Platform section, select Javascript Click Generate SDK. The Javascript SDK for the API will be downloaded by your browser. Extract the file we downloaded in step 3 Find the apigClient.js file inside the folder we extracted and rename this file as apigClient_FlightSpecials.js Open the apigClient_FlightSpecials.js file in the Eclipse IDE. Use Search/Replace and replace apigClientFactory with apigClientFactory_FlightSpecials. There will be 2 occurrences to replace, both at the start of the file. Press Ctrl+F shortcut In the Find section, type apigClientFactory In the Replace with section, type apigClientFactory_FlightSpecials Click Replace All to replace Save Copy the apigClient_FlightSpecials.js file to the api folder inside the www folder inside the working folder for the SPA on your local development environment. Replace the apigClient_FlightSpecials.js file inside the api folder For iDevelop - Hotel Specials API, do the same iDevelop - Flight Specials API Go to AWS API Gateway console Type iDevelop - Hotel Specials API to the search bar and press Enter Click iDevelop - Hotel Specials API Click Stages Select prod Click tab SDK Generation In the Platform section, select Javascript Click Generate SDK. The Javascript SDK for the API will be downloaded by your browser. Extract the file we downloaded in step 8 Find the apigClient.js file inside the folder we extracted and rename this file as apigClient_HotelSpecials.js Open the apigClient_HotelSpecials.js file in the Eclipse IDE. Use Search/Replace and replace apigClientFactory with apigClientFactory_HotelSpecials. Press Ctrl+F shortcut In the Find section, type apigClientFactory In the Replace with section, type apigClientFactory_HotelSpecials Click Replace All to replace Save Copy the apigClient_HotelSpecials.js file to the api folder inside the www folder inside the working folder for the SPA on your local development environment. Replace the apigClient_HotelSpecials.js file inside the api folder For iDevelop - Trip Search API, do the same iDevelop - Flight Specials API Go to AWS API Gateway console Type iDevelop - Trip Search API to the search bar and press Enter Click iDevelop - Trip Search API Click Stages Select prod Click tab SDK Generation In the Platform section, select Javascript Click Generate SDK. The Javascript SDK for the API will be downloaded by your browser. Extract the file we downloaded in step 13 Find the apigClient.js file inside the folder we extracted and rename this file as apigClient_TripSearch.js Open the apigClient_TripSearch.js file in the Eclipse IDE. Use Search/Replace and replace apigClientFactory with apigClientFactory_TripSearch. Press Ctrl+F shortcut In the Find section, type apigClientFactory In the Replace with section, type apigClientFactory_TripSearch Click Replace All to replace Save Copy the apigClient_TripSearch.js file to the api folder inside the www folder inside the working folder for the SPA on your local development environment. Replace the apigClient_TripSearch.js file inside the api folder Push SPA files to Amazon S3 With the API SDKs in place, you are now ready to deploy the SPA code to the Amazon S3 Bucket that will serve the website. The lab setup process has provisioned a suitable S3 bucket, with WebSite Hosting enabled. So you will only need to push all the files from your local machine to the S3 bucket to be able to test the application.\nOpen Command Prompt , navigate to the directory of the www file we extracted in step 1 Execute the following command to synchronize between your local machine and the S3 bucket set AWS_PROFILE=devaxacademy\raws s3 sync . s3://\u0026lt;S3BucketWWWBucketName\u0026gt; --acl public-read Replace \u0026lt;S3BucketWWWBucketName\u0026gt; with the S3BucketWWWBucketName value in the Output tab of the DevAx-06 stack\n18. When the synchronize has completed, you are ready to test your SPA hosted on S3. Open the following URL in the web browser\nhttp://\u0026lt;S3BucketWWWBucketName\u0026gt;.s3-website-\u0026lt;YOUR_REGION\u0026gt;.amazonaws.com Repalce \u0026lt;S3BucketWWWBucketName\u0026gt; with the S3BucketWWWBucketName value in the Output tab of the DevAx-06 stack\nRepalce \u0026lt;YOUR_REGION\u0026gt; with your Region\nThe familiar TravelBuddy website should render in your browser. Previously you have seen this website when it was served from a monolithic Java application served off EC2 managed by Elastic Beanstalk. But now, the site is a single-page web application, and is hosted from an S3 bucket, making API calls to Amazon API Gateway to provide data to the website.\nYou should see the Hotel Specials and Flight Specials listings rendered on the page.\nIn addition, a Find trips to… option is available. To test this, enter Melbourne in the text field and click the Go! button. A dialog will appear showing the results of the search. This data is being served from a call to the TripSearchAPI call, for /tripsfromcity.\nIf you clear the value in the field and click the Go! button, you will see a list of all available trips, which is served from the TripSearchAPI call for /trips.\nIf you are not seeing the data as a result of the API calls, take a look at the developer console in the browser, to see if there are any errors that will help track down the issue.\n"
},
{
	"uri": "/5-tracing-application-performance-with-xray/",
	"title": "Tracing Application Performance With AWS X-Ray",
	"tags": [],
	"description": "",
	"content": "Tracing Application Performance With AWS X-Ray The TripSearch, HotelSpecials and FlightSpecials Lambda functions each contain the necessary dependencies to support emitting tracing events to AWS X-ray, to allow you to easily trace the calls between the components of your distributed system. In this exercise, you will enable the feature and review the AWS X-ray console.\nGo to AWS Lambda console. Click Functions. Type idevelopTripSearchFull to the search bar and press Enter. Click idevelopTripSearchFull. Click Configuration Click Monitoring and operations tools Click Edit In the AWS X-Ray section, enable the Active tracing Click Save Go to the TravelBuddy SPA page. Sign in to the application if you are not already signed in. Click Go! button without any text entered, to invoke the idevelopTripSearchFull Lambda function. It will take a moment to complete. the dialog is shown displaying the trips. Go to AWS CloudWatch Console. Open X-Ray traces. Click Service map Open Legend and options Click Metrics Click Service map, you will see Service map. Go to AWS Lambda console. Click Functions. Type idevelopTripSearchFull to the search bar and press Enter. Click idevelopTripSearchFull. Click Monitor Click Traces You can now also see the service map directly from Lambda console. Back to the AWS CloudWatch Console. Click Service map Click Client Click View traces In the In the Traces list, click the ID of the the first item You will be able to see a timeline view of the various actions and their execution durations Here, you can see that the overall call took 5,98s, 1.67s of which was taken by the scan of the TravelBuddyTripSectors DynamoDB table.\nEnable active tracing on the other Lambda functions that have been created as part of this lab: idevelopTripSearchFull, idevelopTripSearchFromCity, idevelopTripSearchToCity and GetHotelSpecials. You can do this manually using the console. However, note that the function created through automation with a name starting with awscodestar will have its configuration overwritten if you re-deploy the code\n"
},
{
	"uri": "/6-conclusion/",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": "Congratulations! You now have successfully deployed the TravelBuddy website as a Single-Page web Application hosted on Amazon S3, with serverless Lambda microservices served via Amazon API Gateway which also provides throttling, quota management and DDoS protection. You have implemented secure logins via Amazon Cognito, and protected the API calls to require an appropriate bearer token for every call. You have subsequently enabled tracing using Amazon X-ray to provide full visibility to the application’s processing.\nTravelBuddy is ready to ship!\n"
},
{
	"uri": "/2-spa/6-consume-api/",
	"title": "Consume the API",
	"tags": [],
	"description": "",
	"content": "Build a Client to Consume the API\nYou now have a working model of the web site running as an SPA calling for data via RESTful APIs hosted on AWS Lambda, and served from Amazon API Gateway. These data feeds are considered public because the user does not need to be signed-in and provide credentials for the call to the API. In this exercise, we will take a look at how we can require authentication to make the API calls, and the use of API Keys to enforce call-rate throttling and quota management. To demonstrate, we will use a Java client application, to show how you can consume the auto-generated Java SDKs in your applications.\nContents\nCreate Response Model for the TripSearch API Assign the TripsFromCityResponse model to the /tripsfromcity API call Build a Java client application that consumes the API Regenerate the client SDK and install on your development machine Test the newly generated SDK with the Java client app Set the API Key in the client code and re-run the API consumer application with throttling enabled Create Response Model for the TripSearch API In order for the SDK generator to create the appropriate classes for a strongly-typed language like Java (as opposed to Javascript, for example) we need to tell API Gateway what the shape or schema of the request/response objects looks like. In the TripSearch API, we are using the GET method for each of the three API calls. Therefore, there is no schema for inbound requests because the city parameter is passed on as part of the URL. If we instead changed the method to POST, we would need to pass in the city parameter in the body payload, and would need to create a model for this object schema for the code generator to create a Java class for us to bind to.\nThe result data from the API calls is returned in the body of the response. In order for the code generator to create an appropriate class to represent this response, we need to create a response model, and set it as the method response model.\nOpen the API Gateway console and click the Models link beneath iDevelop - Trip Search API. Click Create For Model name type TripsFromCityResponse For Content-type type application/json For Model schema paste in the following description: { \u0026#34;type\u0026#34; : \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34; : { \u0026#34;succeeded\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;boolean\u0026#34; }, \u0026#34;errorMessage\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;string\u0026#34; }, \u0026#34;errorType\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;number\u0026#34; }, \u0026#34;data\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34; : { \u0026#34;date\u0026#34;: { \u0026#34;type\u0026#34; : \u0026#34;number\u0026#34; }, \u0026#34;originCity\u0026#34;: { \u0026#34;type\u0026#34; : \u0026#34;string\u0026#34; }, \u0026#34;destinationCity\u0026#34;: { \u0026#34;type\u0026#34; : \u0026#34;string\u0026#34; }, \u0026#34;airline\u0026#34;: { \u0026#34;type\u0026#34; : \u0026#34;string\u0026#34; } } } } }, \u0026#34;title\u0026#34; : \u0026#34;TripsFromCityResponse\u0026#34; } Click Create model Assign the TripsFromCityResponse model to the /tripsfromcity API call Click the Resources link beneath iDevelop - Trip Search API. Click the GET method beneath /tripsfromcity/{city} Click Method Response In the /tripsfromcity/{city} - GET - Method Response panel, click the arrow next to HTTP Status to reveal the panel Under Response Body for 200 click the pencil icon next to the Empty model. The field becomes a drop-down list. Select TripsFromCityResponse and click the grey tick to commit the change. From the Actions menu, select Deploy API For Deployment stage select prod from the list and click Deploy On the prod Stage Editor that appears, click the SDK Generation tab In the Platform drop-down list, select Java SDK For Service name type TripSearch For Java package name type idevelop.api.sdk Click Generate SDK. The Java SDK will be generated and downloaded as a ZIP file. Explode the downloaded ZIP file on your filesystem. In a terminal window, cd into the folder where the downloaded SDK has been exploded (typically, the directory is called generated-code) and issue the following command: mvn install # if you are using Eclipse IDE on Windows %M2_HOME%\\bin\\mvn install This will compile and install the SDK in your local Maven repository and we will refer to it in the next steps.\nBuild a Java client application that consumes the API Download the source code bundle for a test application from TripSearchJavaClient.zip and explode the zip file onto your filesystem.\nIf you’re using Cloud9, refer to the command below: cd ~/environment curl -L https://workshops.devax.academy/monoliths-to-microservices/module6/files/TripSearchJavaClient.zip --output TripSearchJavaClient.zip unzip TripSearchJavaClient.zip TripSearchJavaClient ource code bundle\rTripSearchJavaClient.zip\r(8 ko)\rIf you’re using Eclipse IDE, use the Open projects from filesystem location menu and browse to the filesystem location where you exploded the TripSearchJavaClient source code. Open the project.\nIf you’re using Cloud9, refer to the command below. cd ~/environment/TripSearchJavaClient mvn install # if you are using Eclipse IDE on Windows %M2_HOME%\\bin\\mvn install Run the project. It will use the TripSearch API to call /tripsfromcity and search for trips with destination Melbourne. You will see an output like this: Got 2 items in 91ms Got 2 items in 91ms Got 2 items in 90ms . . . Got 2 items in 90ms The example API consumer will time how long each call to the API takes, and display the results. It will make a maximum of 100 calls as quickly as it can.\nIf we had many of these clients consuming the API rapidly, we could overwhelm the provisioned infrastructure, so we need some way of throttling calls. We can use Usage Plans to do this.\nOn the API Gateway console, click Usage Plans beneath the APIs navigator panel. Click Create to create a new Usage Plan For Name type LabPlan Under Throttling, for Rate type 1 For Burst type 1 Under Quota type 1000 per month Click Next Click Add API Stage In the API drop-down list, select iDevelop - Trip Search API In the Stage drop-down list, select prod Click the grey tick icon to commit the changes Click Next Click Create API Key and add to Usage Plan In the dialog that appears, for Name type SDKClient Click Save Click Done. A new API key will be created and associated with the usage Plan. Click the iDevelop - Trip Search API link beneath APIs on the left of the API Gateway console. Click the GET method beneath /tripsfromcity/{city} Click Method Request Under Settings, for API Key Required, click the pencil edit icon, and choose true from the list. Click the grey tick icon to commit the change From the Actions menu, select Deploy API Choose the prod stage and click Deploy to deploy the changes Regenerate the client SDK and install on your development machine In the prod Stage Editor, click the SDK Generation tab For Platform, choose Java SDK For Service name type TripSearch For Java package name type idevelop.api.sdk Click Generate SDK. The Java SDK will be generated and downloaded as a ZIP file. Explode the downloaded ZIP file on your filesystem. In a terminal window, cd into the folder where the downloaded SDK has been exploded (typically, the directory is called generated-code) and issue the following command: mvn install This will compile and install the SDK in your local Maven repository, overwriting the previous version. In the following steps, you will use this SDK artefact by referencing it in a client application POM file.\nTest the newly generated SDK with the Java client app In the IDE, re-run the application without making any changes. Since you have set the /tripsfromcity/{GET} endpoint to require an API Key, but have not actually set an API in the client application, you will see a Forbidden error in the console.\nSet the API Key in the client code and re-run the API consumer application with throttling enabled The provided client source code needs to be updated to set the API Key in order to successfully call the /tripsfromcity/{GET} method. On the AWS API Gateway Console, click the API Keys tab Click the SDKClient link Click the Show link next to API Key to reveal the auto-generated API key. Copy the value into your clipboard. In the IDE, in the /src/main/java/idevelop/api/tripsearch/sdk/app/App.java file, paste in the API Key in your clipboard, in the API_KEY definition, replacing the \u0026lt;REPLACE_WITH_API_KEY\u0026gt; placeholder. In the same file, locate the commented out call to apiKey(API_KEY) in the TripSearch builder call. You may have to run a Maven Update on the project to pick up the .apiKey as we updated the jar in the last step and Eclipse may not have picked it up. Now that you have required an API Key in the API Gateway call, the SDK created for you will contain a call to allow the key to be set. If you have no API Key requirements, the code generator does not emit this functionality so in the provided code, it is commented out. You need to enable the call in the client code to allow the API Key to be set correctly. Re-run the application in the IDE. Notice that the calls will now succeed, but, you will now periodically start receiving errors requesting you slow down the call-rate. This is because we set a maximum call-rate of 1 call per second per API key. You will see output like this: Got 2 items in 97ms Got 2 items in 125ms Too Many Requests - waiting 1 second... . . . As an experiment, edit the API_KEY you have set in the App class (for example, add a period at the end) which will cause it to be invalid. Re-run the app and notice that you now receive a Forbidden message. This is because you set the API Key as required for calls to the /tripsfromcity call. Experiment with the Rate and Burst settings in the Usage Plan to see how they affect the client app calling the API. Note that you do not need to re-deploy the API nor re-create the SDK if you change the settings in the Usage Plan.\n"
},
{
	"uri": "/3-create-single-page-app/3.6-build-api-consumer/",
	"title": "Build A Client To Consume The API",
	"tags": [],
	"description": "",
	"content": "Build A Client To Consume The API You now have a working model of the web site running as an SPA calling for data via RESTful APIs hosted on AWS Lambda, and served from Amazon API Gateway. These data feeds are considered public because the user does not need to be signed-in and provide credentials for the call to the API. In this exercise, we will take a look at how we can require authentication to make the API calls, and the use of API Keys to enforce call-rate throttling and quota management. To demonstrate, we will use a Java client application, to show how you can consume the auto-generated Java SDKs in your applications.\nCreate Response Model for the TripSearch API In order for the SDK generator to create the appropriate classes for a strongly-typed language like Java (as opposed to Javascript, for example) we need to tell API Gateway what the shape or schema of the request/response objects looks like. In the TripSearch API, we are using the GET method for each of the three API calls. Therefore, there is no schema for inbound requests because the city parameter is passed on as part of the URL. If we instead changed the method to POST, we would need to pass in the city parameter in the body payload, and would need to create a model for this object schema for the code generator to create a Java class for us to bind to.\nThe result data from the API calls is returned in the body of the response. In order for the code generator to create an appropriate class to represent this response, we need to create a response model, and set it as the method response model.\nGo to AWS API Gateway console Type iDevelop - Trip Search API to the search bar and press Enter Click iDevelop - Trip Search API Click Models Click Create In the Model name section, type TripsFromCityResponse In the Content-type section, type application/json In the Model schema section, type {\r\u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;,\r\u0026#34;properties\u0026#34;: {\r\u0026#34;succeeded\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34;\r},\r\u0026#34;errorMessage\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;\r},\r\u0026#34;errorType\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;number\u0026#34;\r},\r\u0026#34;data\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;,\r\u0026#34;items\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;,\r\u0026#34;properties\u0026#34;: {\r\u0026#34;date\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;number\u0026#34;\r},\r\u0026#34;originCity\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;\r},\r\u0026#34;destinationCity\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;\r},\r\u0026#34;airline\u0026#34;: {\r\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;\r}\r}\r}\r}\r},\r\u0026#34;title\u0026#34;: \u0026#34;TripsFromCityResponse\u0026#34;\r} Click Create model Assign the TripsFromCityResponse model to the /tripsfromcity API call Click Resources Click the GET method beneath /tripsfromcity/{city} Click Method Response In the /tripsfromcity/{city} - GET - Method Response panel, click the arrow next to HTTP Status to reveal the panel Under Response Body for 200 click the pencil icon next to the Empty model. The field becomes a drop-down list. Select TripsFromCityResponse Click the grey tick to commit the change Click Actions Click Deploy API In the Deployment stage section, select prod Click Deploy On the prod Stage Editor that appears, click SDK Generation In the Platform section, select Java SDK In the Service name section, type TripSearch In the Java package name section, type idevelop.api.sdk Click Generate SDK. The Java SDK will be generated and downloaded as a ZIP file. Extract the downloaded ZIP file we downloaded in step 8 Open Command Prompt and navigate to the directory of the downloaded SDK has been exploded (the directory is called generated-code) Execute the following command mvn install This will compile and install the SDK in your local Maven repository and we will refer to it in the next steps.\nBuild a Java client application that consumes the API TripSearchJavaClient Project\rTripSearchJavaClient.zip\r(8 ko)\rDownload the TripSearchJavaClient.zip file and extract In the Eclipse IDE, open the project we extracted in step 10 Open the pom.xml file Replace the pom.xml file contents with the following: \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34;\rxsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\u0026#34;\u0026gt;\r\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\r\u0026lt;groupId\u0026gt;idevelop.api.tripsearch.sdk.app\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;TripSearch-sdkClient\u0026lt;/artifactId\u0026gt;\r\u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt;\r\u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;name\u0026gt;TripSearch-sdkClient\u0026lt;/name\u0026gt;\r\u0026lt;url\u0026gt;http://maven.apache.org\u0026lt;/url\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;maven.compiler.source\u0026gt;1.8\u0026lt;/maven.compiler.source\u0026gt;\r\u0026lt;maven.compiler.target\u0026gt;1.8\u0026lt;/maven.compiler.target\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;idevelop.api.sdk\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;TripSearch\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;build\u0026gt;\r\u0026lt;plugins\u0026gt;\r\u0026lt;plugin\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.2.4\u0026lt;/version\u0026gt;\r\u0026lt;executions\u0026gt;\r\u0026lt;execution\u0026gt;\r\u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt;\r\u0026lt;goals\u0026gt;\r\u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt;\r\u0026lt;/goals\u0026gt;\r\u0026lt;configuration\u0026gt;\r\u0026lt;transformers\u0026gt;\r\u0026lt;transformer implementation=\u0026#34;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026#34;\u0026gt;\r\u0026lt;mainClass\u0026gt;idevelop.api.tripsearch.sdk.app.App\u0026lt;/mainClass\u0026gt;\r\u0026lt;/transformer\u0026gt;\r\u0026lt;/transformers\u0026gt;\r\u0026lt;/configuration\u0026gt;\r\u0026lt;/execution\u0026gt;\r\u0026lt;/executions\u0026gt;\r\u0026lt;/plugin\u0026gt;\r\u0026lt;/plugins\u0026gt;\r\u0026lt;/build\u0026gt;\r\u0026lt;/project\u0026gt; 12. In the Command Prompt, navigate to the directory of the project we extracted in step 10\nExecute the following command mvn package 13. Execute the following command to run project\njava -jar target/TripSearch-sdkClient-1.0-SNAPSHOT.jar You will see an output. The example API consumer will time how long each call to the API takes, and display the results. It will make a maximum of 100 calls as quickly as it can.\nIf we had many of these clients consuming the API rapidly, we could overwhelm the provisioned infrastructure, so we need some way of throttling calls. We can use Usage Plans to do this.\nGo to AWS API Gateway console Type iDevelop - Trip Search API to the search bar and press Enter Click iDevelop - Trip Search API Click Usage Plans Click Create In the Name section, type LabPlan In the Rate section, type 1 In the Burst section, type 1 In the Quota section, type 1000 per month Click Next Click Add API Stage In the API drop-down list, select iDevelop - Trip Search API In the Stage drop-down list, select prod Click the grey tick icon to commit the changes Click Next CLick Create API Key and add to Usage Plan In the dialog that appears, for Name type SDKClient Click Save Click Done, A new API key will be created and associated with the usage Plan. Click iDevelop - Trip Search API Click the GET method beneath /tripsfromcity/{city} Click Method Request In the API Key Required section, click the pencil edit icon Select True Click the grey tick icon to commit the change Click Actions Click Deploy API In the dialog that appears: In the Deployment stage section, select prod Click Deploy In the prod Stage Editor, click SDK Generation In the Platform section, select Java SDK In the Service name section, type TripSearch In the Java package name section, type idevelop.api.sdk Click Generate SDK. The Java SDK will be generated and downloaded as a ZIP file. Extract the ZIP file we downloaded in step 26 Open Command Prompt and navigate to the directory of the downloaded SDK has been exploded (the directory is called generated-code) Execute the following command mvn install This will compile and install the SDK in your local Maven repository, overwriting the previous version.\nTest the newly generated SDK with the Java client app In the Command Prompt, navigate to the directory of the project we extracted in step 10 Execute the following command to run application java -jar target/TripSearch-sdkClient-1.0-SNAPSHOT.jar Since you have set the /tripsfromcity/{GET} endpoint to require an API Key, but have not actually set an API in the client application, you will see a Forbidden error Set the API Key in the client code and re-run the API consumer application with throttling enabled Click API Keys Click SDKClient In the API Key section, click show to show the auto-generated API key Save the API key in the API key section In the Eclipse IDE, open the file whose the path is /src/main/java/idevelop/api/tripsearch/sdk/app/App.java Replace \u0026lt;REPLACE_WITH_API_KEY\u0026gt; with the API key value we saved in step 30 In the same file, locate the commented out call to apiKey(API_KEY) in the TripSearch builder call. You may have to run a Maven Update on the project to pick up the .apiKey as we updated the jar in the last step and Eclipse may not have picked it up. Now that you have required an API Key in the API Gateway call, the SDK created for you will contain a call to allow the key to be set. If you have no API Key requirements, the code generator does not emit this functionality so in the provided code, it is commented out. You need to enable the call in the client code to allow the API Key to be set correctly. Save In the Eclipse IDE, right-click on the TripSearch-sdkClient project Click Maven Click Update Project\u0026hellip; In the Command Prompt, execute the following command mvn package 34. In the Command Prompt, execute the following command\njava -jar target/TripSearch-sdkClient-1.0-SNAPSHOT.jar 35. You will now periodically start receiving errors requesting you slow down the call-rate. This is because we set a maximum call-rate of 1 call per second per API key. You will see a output 36. As an experiment, edit the API_KEY you have set in the App class (for example, add a period at the end) which will cause it to be invalid. Re-run the app and notice that you now receive a Forbidden message. This is because you set the API Key as required for calls to the /tripsfromcity call. 37. In the Command Prompt, execute the following command\njava -jar target/TripSearch-sdkClient-1.0-SNAPSHOT.jar You will see a output Experiment with the Rate and Burst settings in the Usage Plan to see how they affect the client app calling the API you do not need to re-deploy the API nor re-create the SDK if you change the settings in the Usage Plan.\n"
},
{
	"uri": "/6-challenge/",
	"title": "Challenge",
	"tags": [],
	"description": "",
	"content": "Challenge As an optional task, you are challenged with implementing active tracing using automation for the functions deployed using the AWS CLI and CodeStar. We are not going to give you all the answers! But to help you on your journey, check out the AWS::Lambda::Function tCloudFormation documentation, and AWS SAM documentation.\nWhen you have fully implemented tracing for the Lambda functions, you will see the tracing segments on the AWS X-ray console. Trigger the execution of the various lambda functions using the TravelBuddy SPA web page, and you will see results such as:\n"
},
{
	"uri": "/7-resources/",
	"title": "Reference resources",
	"tags": [],
	"description": "",
	"content": "Useful resources for you to refer to:\nAWS Cognito:\nhttps://aws.amazon.com/cognito/faqs/ https://docs.aws.amazon.com/cognito/latest/developerguide/iam-roles.html https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-identity.html https://aws.amazon.com/blogs/mobile/use-amazon-cognito-in-your-website-for-simple-aws-authentication/ https://forums.aws.amazon.com/forum.jspa?forumID=173 CORS explained:\nhttps://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html https://aws.amazon.com/blogs/aws/amazon-s3-cross-origin-resource-sharing/ API G/W:\nhttps://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-mapping-template-reference.html S3:\nhttps://aws.amazon.com/blogs/storage/protect-amazon-s3-buckets-using-access-analyzer-for-s3/ https://www.youtube.com/watch?v=rHeTn9pHNKo Fielding\nhttps://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm https://www.ics.uci.edu/~fielding/pubs/dissertation/fielding_dissertation.pdf https://restfulapi.net/hateoas/ https://martinfowler.com/articles/richardsonMaturityModel.html "
},
{
	"uri": "/7-cleanup/",
	"title": "Clean up resources",
	"tags": [],
	"description": "",
	"content": "You clean up resources in the following order:\nTerminate EC2 Instance Go to Amazon EC2 console. On the left navigation bar, click Intances. Select DevAxWindowsHost. Click Instance state Click Terminate instance Click Terminate Delete Users Go to AWS IAM Console. Click Users. Type awsstudent to the search bar Select awsstudent. Click Delete Type awsstudent to confirm, then click Delete Delete policy Go to AWS IAM Console. Click Policies. Type idevelop to the search bar and press Enter Select idevelopCodeStarCloudFormationPolicy Click Actions Click Delete Type the name of the policy to confirm, then click Delete to delete Delete DynamoDB Go to AWS DynamoDB Console. Click Tables Select all the DynamoDB we create Click Actions Click Delete Type delete to confirm, then click Delete to delete Delete API Gateway Go to AWS API Gateway console. Selet iDevelop - Trip Search API Click Actions Click Delete Click Delete to delete Delete CodeStar Go to AWS CodeStar Console. Click Projects Select FlightSpecialsAPI Click Delete Type delete to confirm, then click Delete to delete Delete CloudFormation Stack Go to AWS CloudFormation Console. Select DevAx-06. Click Delete Click Delete stack Do the same for the other CloudFormation Stacks Delete S3 bucket Go to AWS S3 Console. Click Buckets Select aws-codestart-us-east-1\u0026hellip;. Click Empty. Type permanently delete to confirm, then click Empty to delete the data of this S3 bucket. Click Exit to back to the S3 inteface. Click Delete. Type the name of the bucket then click Delete bucket to delete S3 bucket. Do the same for the other S3 bucket "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]